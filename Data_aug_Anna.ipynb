{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cdbc5f1-51c3-4906-b156-03018fb72b93",
   "metadata": {},
   "source": [
    "#### Data Augmetation: several tries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608d73c-b58f-4944-8295-bc0e29150162",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5bbbdc2-4db4-4544-9194-2f194157fd53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "download = False\n",
    "\n",
    "if download:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "path_articles = DATA_PATH + \"articles_plain_text/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e0a2b70-91eb-4ee5-b8e4-c7459a035f16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topics = pd.read_csv(DATA_PATH + \"topics_articles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178fc748-794c-412d-8f65-74c1af66f5d1",
   "metadata": {},
   "source": [
    "#### Compare 3 clich√©s and 3 random articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dcc7dd4-d55d-4dfb-a665-67f06227a15c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Articles to compare\n",
    "articles_to_compare_1 = [\"Viking.txt\", \"Leonardo_da_Vinci.txt\", \"Venus.txt\"]\n",
    "articles_to_compare_2 = [\"William_Shakespeare.txt\", \"London.txt\", \"BBC.txt\"]\n",
    "\n",
    "# Filter DataFrame\n",
    "df_compare_1 = topics[topics['article_name'].isin(articles_to_compare_1)]\n",
    "df_compare_2 = topics[topics['article_name'].isin(articles_to_compare_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9703b0c-e068-4e94-a960-9429b299bb82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_compare_2[['article_name', 'topics']].to_csv(DATA_PATH + \"compare_2_topics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2d01792-0922-4460-97d7-91a0192b07b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# United Kingdom topics\n",
    "uk_topics_row = topics[topics['article_name'] == 'United_Kingdom.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39d4aa1f-baf1-443f-9d5c-9dfcf641646c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_name</th>\n",
       "      <th>topics</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>United_Kingdom.txt</td>\n",
       "      <td>['government' 'royalty' 'medieval' 'military' ...</td>\n",
       "      <td>[0.2 0.2 0.2 0.2 0.2 0.  0.  0.  0.  0. ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            article_name                                             topics  \\\n",
       "4293  United_Kingdom.txt  ['government' 'royalty' 'medieval' 'military' ...   \n",
       "\n",
       "                                     confidence  \n",
       "4293  [0.2 0.2 0.2 0.2 0.2 0.  0.  0.  0.  0. ]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_topics_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51ec19a8-341a-4394-bf7d-33f077601598",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common topics for Leonardo_da_Vinci.txt and United Kingdom: {\"'money'\", \"'help'\", \"'dance'\"}\n",
      "Common topics for Venus.txt and United Kingdom: {\"'money'\", \"'help'\", \"'dance'\"}\n",
      "Common topics for Viking.txt and United Kingdom: {\"'money'\", \"'help'\", \"'dance'\"}\n",
      "Common topics for BBC.txt and United Kingdom: set()\n",
      "Common topics for London.txt and United Kingdom: {\"'money'\", \"'help'\", \"'dance'\"}\n",
      "Common topics for William_Shakespeare.txt and United Kingdom: {\"'office'\\n\", \"'help'\"}\n"
     ]
    }
   ],
   "source": [
    "# Check if the United Kingdom is in the DataFrame\n",
    "if not uk_topics_row.empty:\n",
    "    uk_topics = uk_topics_row.iloc[0]['topics']\n",
    "\n",
    "    # Compare topics\n",
    "    def compare_topics(topics_str1, topics_str2):\n",
    "        # Convert string representations to actual lists\n",
    "        list1 = topics_str1.split(' ')\n",
    "        list2 = topics_str2.split(' ')\n",
    "\n",
    "        set1 = set(list1)\n",
    "        set2 = set(list2)\n",
    "        common_topics = set1 & set2\n",
    "        return common_topics\n",
    "\n",
    "    # Compare topics for df_compare_1\n",
    "    for index, row in df_compare_1.iterrows():\n",
    "        common_topics = compare_topics(row['topics'], uk_topics)\n",
    "        print(f\"Common topics for {row['article_name']} and United Kingdom: {common_topics}\")\n",
    "\n",
    "    # Compare topics for df_compare_2\n",
    "    for index, row in df_compare_2.iterrows():\n",
    "        common_topics = compare_topics(row['topics'], uk_topics)\n",
    "        print(f\"Common topics for {row['article_name']} and United Kingdom: {common_topics}\")\n",
    "else:\n",
    "    print(\"United Kingdom not found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdcaa74-71c9-49ed-9d02-306305959e35",
   "metadata": {},
   "source": [
    "#### Compare 10 random articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d21a92c3-3f26-4663-acfb-18e0c6bbb41d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common topics for Cataract_surgery.txt and United Kingdom: {\"'help'\", \"'dance'\", \"'office'\\n\", \"'money'\", \"'wedding']\"}\n",
      "Common topics for Cuckmere_Haven.txt and United Kingdom: set()\n",
      "Common topics for Henry_I_of_England.txt and United Kingdom: {\"'power'\", \"'royalty'\", \"'medieval'\", \"'dance'\"}\n",
      "Common topics for Gaborone.txt and United Kingdom: {\"'money'\", \"'dance'\"}\n",
      "Common topics for 11th_century.txt and United Kingdom: {\"'office'\\n\", \"'money'\", \"'help'\", \"'dance'\"}\n",
      "Common topics for Middle_Ages.txt and United Kingdom: {\"'money'\", \"'help'\", \"'dance'\"}\n",
      "Common topics for Sun_Tzu.txt and United Kingdom: {\"'office'\\n\", \"'help'\"}\n",
      "Common topics for List_of_sovereign_states.txt and United Kingdom: {\"'money'\", \"'help'\", \"'dance'\", \"['government'\"}\n",
      "Common topics for Antananarivo.txt and United Kingdom: {\"'money'\", \"'dance'\"}\n",
      "Common topics for Cymbopogon.txt and United Kingdom: {\"'money'\", \"'help'\", \"'dance'\"}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(16)\n",
    "\n",
    "# Randomly select 10 articles\n",
    "random_articles = topics.sample(n=10)\n",
    "\n",
    "# United Kingdom topics\n",
    "uk_topics_row = topics[topics['article_name'] == 'United_Kingdom.txt']\n",
    "\n",
    "# Check if the United Kingdom is in the DataFrame\n",
    "if not uk_topics_row.empty:\n",
    "    uk_topics = uk_topics_row.iloc[0]['topics']\n",
    "\n",
    "    # Function to compare topics\n",
    "    def compare_topics(topics_str1, topics_str2):\n",
    "        # Convert string representations to actual lists\n",
    "        list1 = topics_str1.split(' ')\n",
    "        list2 = topics_str2.split(' ')\n",
    "\n",
    "        set1 = set(list1)\n",
    "        set2 = set(list2)\n",
    "        common_topics = set1 & set2\n",
    "        return common_topics\n",
    "\n",
    "    # Compare topics for the randomly selected articles\n",
    "    for index, row in random_articles.iterrows():\n",
    "        common_topics = compare_topics(row['topics'], uk_topics)\n",
    "        print(f\"Common topics for {row['article_name']} and United Kingdom: {common_topics}\")\n",
    "\n",
    "    # Save 'topics' column of random_articles to a CSV file\n",
    "    random_articles[['article_name', 'topics']].to_csv(DATA_PATH + \"random_articles_topics.csv\", index=False)\n",
    "else:\n",
    "    print(\"United Kingdom not found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6956e2b2-622a-4d95-933c-14434352c314",
   "metadata": {},
   "source": [
    "#### Entire set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f2ca8df-4d88-4134-98c5-c2c4325a7b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 comparisons with most common topics:\n",
      "United_Kingdom.txt and United Kingdom: {\"'military'\", \"'help'\", \"'dance'\", \"'office'\\n\", \"'medieval'\", \"'power'\", \"['government'\", \"'royalty'\", \"'money'\", \"'wedding']\"}\n",
      "William_Renshaw.txt and United Kingdom: {\"'military'\", \"'help'\", \"'dance'\", \"'office'\\n\", \"'medieval'\", \"'power'\", \"['government'\", \"'royalty'\", \"'money'\", \"'wedding']\"}\n",
      "Colditz_Castle.txt and United Kingdom: {\"'help'\", \"'dance'\", \"'office'\\n\", \"'medieval'\", \"'royalty'\", \"'money'\", \"'wedding']\"}\n",
      "Force.txt and United Kingdom: {\"'military'\", \"'help'\", \"'dance'\", \"'office'\\n\", \"'power'\", \"'money'\", \"'wedding']\"}\n",
      "Haji_Mohammad_Suharto.txt and United Kingdom: {\"'military'\", \"'help'\", \"'dance'\", \"'office'\\n\", \"'power'\", \"'money'\", \"'wedding']\"}\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for reproducibility\n",
    "np.random.seed(47)\n",
    "\n",
    "# United Kingdom topics\n",
    "uk_topics_row = topics[topics['article_name'] == 'United_Kingdom.txt']\n",
    "\n",
    "# Check if the United Kingdom is in the DataFrame\n",
    "if not uk_topics_row.empty:\n",
    "    uk_topics = uk_topics_row.iloc[0]['topics']\n",
    "\n",
    "    # Function to compare topics\n",
    "    def compare_topics(topics_str1, topics_str2):\n",
    "        # Convert string representations to actual lists\n",
    "        list1 = topics_str1.split(' ')\n",
    "        list2 = topics_str2.split(' ')\n",
    "\n",
    "        set1 = set(list1)\n",
    "        set2 = set(list2)\n",
    "        common_topics = set1 & set2\n",
    "        return common_topics\n",
    "\n",
    "    # Compare topics for all articles in the dataset\n",
    "    comparisons_with_common_topics = []\n",
    "\n",
    "    for index, row in topics.iterrows():\n",
    "        common_topics = compare_topics(row['topics'], uk_topics)\n",
    "        if common_topics:\n",
    "            comparisons_with_common_topics.append({'article_name': row['article_name'], 'common_topics': common_topics})\n",
    "\n",
    "    # Sort comparisons based on the number of common topics\n",
    "    comparisons_with_common_topics.sort(key=lambda x: len(x['common_topics']), reverse=True)\n",
    "\n",
    "    # Print the top 5 comparisons\n",
    "    print(\"Top 5 comparisons with most common topics:\")\n",
    "    for i in range(min(5, len(comparisons_with_common_topics))):\n",
    "        print(f\"{comparisons_with_common_topics[i]['article_name']} and United Kingdom: {comparisons_with_common_topics[i]['common_topics']}\")\n",
    "\n",
    "    # Save the top 50 comparisons to a CSV file\n",
    "    top_50_comparisons = comparisons_with_common_topics[:50]\n",
    "    if top_50_comparisons:\n",
    "        df_top_50_comparisons = pd.DataFrame(top_50_comparisons)\n",
    "        df_top_50_comparisons.to_csv(DATA_PATH + \"top_50_common_topics.csv\", index=False)\n",
    "else:\n",
    "    print(\"United Kingdom not found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e0034b-83ee-40de-a759-a840e1ff279c",
   "metadata": {},
   "source": [
    "##### Additional analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64e57acc-c483-4273-bfb8-82de66b76123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "Topics for Gallery_of_the_Kings_and_Queens_of_England.txt: ['domestic_work' 'royalty' 'real_estate' 'home' 'medieval' 'power' 'party'\n",
      " 'help' 'office' 'dance']\n",
      "Topics for United_Kingdom.txt: ['government' 'royalty' 'medieval' 'military' 'power' 'help' 'office'\n",
      " 'dance' 'money' 'wedding']\n",
      "Common topics between Gallery_of_the_Kings_and_Queens_of_England.txt and United_Kingdom.txt: {\"'medieval'\", \"'royalty'\", \"'help'\", \"'power'\"}\n"
     ]
    }
   ],
   "source": [
    "# Assuming df_topics is your DataFrame\n",
    "\n",
    "# Find the row for 'Gallery_of_the_Kings_and_Queens_of_England.txt'\n",
    "article_row = topics[topics['article_name'] == 'Gallery_of_the_Kings_and_Queens_of_England.txt']\n",
    "\n",
    "# United Kingdom topics\n",
    "uk_topics_row = topics[topics['article_name'] == 'United_Kingdom.txt']\n",
    "\n",
    "# Check if the article and United Kingdom are in the DataFrame\n",
    "if not article_row.empty and not uk_topics_row.empty:\n",
    "    article_topics = article_row.iloc[0]['topics']\n",
    "    uk_topics = uk_topics_row.iloc[0]['topics']\n",
    "\n",
    "    # Print topics for the article and the United Kingdom\n",
    "    print(article_topics[1])\n",
    "    print(f\"Topics for Gallery_of_the_Kings_and_Queens_of_England.txt: {article_topics}\")\n",
    "    print(f\"Topics for United_Kingdom.txt: {uk_topics}\")\n",
    "\n",
    "    # Function to compare topics\n",
    "    def compare_topics(topics_str1, topics_str2):\n",
    "        # Convert string representations to actual lists\n",
    "        list1 = topics_str1.split(' ')\n",
    "        list2 = topics_str2.split(' ')\n",
    "\n",
    "        set1 = set(list1)\n",
    "        set2 = set(list2)\n",
    "        common_topics = set1 & set2\n",
    "        return common_topics\n",
    "\n",
    "    # Compare topics for the article and the United Kingdom\n",
    "    common_topics = compare_topics(article_topics, uk_topics)\n",
    "    print(f\"Common topics between Gallery_of_the_Kings_and_Queens_of_England.txt and United_Kingdom.txt: {common_topics}\")\n",
    "else:\n",
    "    print(\"Article or United Kingdom not found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49015ae-a3fa-48b6-994e-aa9b4f662274",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3100333-920a-444a-8524-5b63f8673cec",
   "metadata": {},
   "source": [
    "#### Get most common words and Proper nouns from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16808c5-e38c-4c7a-b5ed-35d2b84b675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1d5bf3-e523-4142-a2be-0a472089b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = PlaintextCorpusReader(\n",
    "    path_articles, \".*.txt\", encoding=\"utf8\"\n",
    ").fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681758a-6a2a-4def-9af7-9d4e37e1636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last try\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "\n",
    "# Load spaCy model and NLTK stop words\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Process the text using spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract tokens and part-of-speech tags\n",
    "    tokens_pos = [(token.text, token.pos_) for token in doc]\n",
    "\n",
    "    # Remove stop words and non-alphabetic words\n",
    "    filtered_tokens_pos = [\n",
    "        (word, 'NOUN' if word.istitle() and pos != 'PROPN' else pos)\n",
    "        for word, pos in tokens_pos\n",
    "        if word.isalpha() and word.lower() not in stop_words\n",
    "    ]\n",
    "\n",
    "    return filtered_tokens_pos\n",
    "\n",
    "# List to store preprocessed documents\n",
    "docs = []\n",
    "\n",
    "for article_name in all_articles:\n",
    "    with open(path_articles + article_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Preprocess the text\n",
    "    preprocessed_tokens_pos = preprocess_text(text)\n",
    "\n",
    "    # Append preprocessed tokens to the docs list\n",
    "    docs.append(preprocessed_tokens_pos)\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = \"preprocessed_data.csv\"\n",
    "\n",
    "# Write the preprocessed data to the CSV file\n",
    "with open(csv_file_path, mode='w', encoding='utf-8', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write header\n",
    "    csv_writer.writerow([\"Article\", \"Tokens_POS\"])\n",
    "    \n",
    "    # Write data\n",
    "    for i, article_tokens_pos in enumerate(docs):\n",
    "        csv_writer.writerow([all_articles[i], article_tokens_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee5e66cf-ad4d-4a68-a30e-1ef127c088be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 comparisons with most common proper nouns:\n",
      "United_Kingdom.txt and United_Kingdom.txt: {'UK', 'United', 'England', 'Ireland', 'Northern', 'Scotland', 'Wales', 'British', 'Kingdom', 'London'}\n",
      "United_Kingdom_national_football_team.txt and United_Kingdom.txt: {'UK', 'United', 'Ireland', 'Northern', 'Scotland', 'Kingdom', 'England'}\n",
      "Pound_sterling.txt and United_Kingdom.txt: {'UK', 'United', 'Ireland', 'Northern', 'Scotland', 'Kingdom', 'England'}\n",
      "Great_Britain.txt and United_Kingdom.txt: {'United', 'Northern', 'Ireland', 'Scotland', 'British', 'Kingdom', 'England'}\n",
      "British_English.txt and United_Kingdom.txt: {'UK', 'England', 'Ireland', 'Scotland', 'British', 'London'}\n",
      "Top comparisons with most common proper nouns saved to data/top_proper_noun_comparisons.csv\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "# Load the preprocessed data\n",
    "tokens_and_pos = pd.read_csv(DATA_PATH + \"preprocessed_data.csv\")\n",
    "\n",
    "# Replace 'United_Kingdom.txt' with the target article name\n",
    "target_article_name = 'United_Kingdom.txt'\n",
    "\n",
    "# Filter rows related to the target article\n",
    "target_article_data = tokens_and_pos[tokens_and_pos['Article'] == target_article_name]\n",
    "\n",
    "# Check if the target article is present in the DataFrame\n",
    "if not target_article_data.empty:\n",
    "    # Extract the top 10 PROPN tokens for the target article\n",
    "    target_proper_nouns = [token[0] for tokens_pos_list in target_article_data['Tokens_POS'] for token in eval(tokens_pos_list) if token[1] == 'PROPN']\n",
    "    top_target_proper_nouns = [item[0] for item in Counter(target_proper_nouns).most_common(10)]\n",
    "\n",
    "    # Initialize a list to store common proper nouns\n",
    "    common_proper_nouns = []\n",
    "\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in tokens_and_pos.iterrows():\n",
    "        # Extract the top 10 PROPN tokens for each article\n",
    "        article_proper_nouns = [token[0] for token in eval(row['Tokens_POS']) if token[1] == 'PROPN']\n",
    "        top_article_proper_nouns = [item[0] for item in Counter(article_proper_nouns).most_common(10)]\n",
    "\n",
    "        # Compare with the top PROPN tokens of the target article\n",
    "        common_tokens = set(top_article_proper_nouns) & set(top_target_proper_nouns)\n",
    "\n",
    "        # Store the results\n",
    "        common_proper_nouns.append({'Article': row['Article'], 'Common_Propnouns': common_tokens})\n",
    "\n",
    "    # Convert the results to a DataFrame\n",
    "    common_proper_nouns_df = pd.DataFrame(common_proper_nouns)\n",
    "\n",
    "    # Sort the DataFrame based on the number of common proper nouns\n",
    "    common_proper_nouns_df = common_proper_nouns_df.sort_values(by='Common_Propnouns', key=lambda x: x.str.len(), ascending=False)\n",
    "\n",
    "    # Print the top 5 comparisons\n",
    "    print(\"Top 5 comparisons with most common proper nouns:\")\n",
    "    for i in range(min(5, len(common_proper_nouns_df))):\n",
    "        print(f\"{common_proper_nouns_df.iloc[i]['Article']} and {target_article_name}: {common_proper_nouns_df.iloc[i]['Common_Propnouns']}\")\n",
    "\n",
    "    # Save the top comparisons to a CSV file\n",
    "    top_comparisons = common_proper_nouns_df.head(50)\n",
    "    if not top_comparisons.empty:\n",
    "        top_comparisons.to_csv(DATA_PATH + \"top_proper_noun_comparisons.csv\", index=False)\n",
    "        print(f\"Top comparisons with most common proper nouns saved to {DATA_PATH}top_proper_noun_comparisons.csv\")\n",
    "    else:\n",
    "        print(\"No common proper nouns found.\")\n",
    "else:\n",
    "    print(f\"{target_article_name} not found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec14a023-d403-4a5e-b258-b81465faffb2",
   "metadata": {},
   "source": [
    "### Links and proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a77b9ba-c8d9-4701-9de9-37d28f99ebbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated DataFrame:\n",
      "                    article  \\\n",
      "0         √Åed√°n_mac_Gabr√°in   \n",
      "1                     √Öland   \n",
      "2             √âdouard_Manet   \n",
      "3                      √âire   \n",
      "4     √ìengus_I_of_the_Picts   \n",
      "...                     ...   \n",
      "4582                Zionism   \n",
      "4583              Zirconium   \n",
      "4584              Zoroaster   \n",
      "4585           Zuid-Gelders   \n",
      "4586                   Zulu   \n",
      "\n",
      "                                        common_articles  \\\n",
      "0     ['Orkney', 'Isle_of_Man', 'Monarchy', 'Great_B...   \n",
      "1     ['Time_zone', 'World_War_II', 'Currency', 'Eur...   \n",
      "2     ['Germany', 'United_States_dollar', 'Italy', '...   \n",
      "3     ['English_language', 'Ireland', 'Republic_of_I...   \n",
      "4     ['Lion', 'Great_Britain', 'Ireland', 'Scotland...   \n",
      "...                                                 ...   \n",
      "4582  ['Argentina', 'United_Nations', 'World_War_II'...   \n",
      "4583          ['Steel', 'Electron', 'Bicycle', 'India']   \n",
      "4584                          ['Christianity', 'India']   \n",
      "4585                                                 []   \n",
      "4586               ['Christianity', 'English_language']   \n",
      "\n",
      "                                           common_propn  \n",
      "0     [Monarchy, Great_Britain, Ireland, Scotland, W...  \n",
      "1                                [European_Union, Euro]  \n",
      "2                              [Germany, Italy, France]  \n",
      "3                   [Ireland, Northern_Ireland, Canada]  \n",
      "4     [Lion, Great_Britain, Ireland, Scotland, England]  \n",
      "...                                                 ...  \n",
      "4582  [Argentina, Europe, British_Empire, Italy, Ind...  \n",
      "4583                  [Steel, Electron, Bicycle, India]  \n",
      "4584                              [Christianity, India]  \n",
      "4585                                                 []  \n",
      "4586                                     [Christianity]  \n",
      "\n",
      "[4587 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import ast\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load the data from the CSV file\n",
    "csv_file_path = \"data/links_common.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Function to extract proper nouns from a list of words\n",
    "def extract_proper_nouns(words):\n",
    "    words_list = ast.literal_eval(words)  # Convert string to list\n",
    "    doc = nlp(\" \".join(words_list))\n",
    "    proper_nouns = [token.text for token in doc if token.pos_ == 'PROPN' and token.text.istitle()]\n",
    "    return proper_nouns\n",
    "\n",
    "# Apply the function to the 'common_articles' column and create a new column 'common_propn'\n",
    "df['common_propn'] = df['common_articles'].apply(extract_proper_nouns)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "new_csv_file_path = \"data/links_common_updated.csv\"\n",
    "df.to_csv(new_csv_file_path, index=False)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"\\nUpdated DataFrame:\")\n",
    "print(df[['article', 'common_articles', 'common_propn']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9376d31-cc65-4bdc-987b-d45b5c277bba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated DataFrame:\n",
      "                    article  \\\n",
      "0         √Åed√°n_mac_Gabr√°in   \n",
      "1                     √Öland   \n",
      "2             √âdouard_Manet   \n",
      "3                      √âire   \n",
      "4     √ìengus_I_of_the_Picts   \n",
      "...                     ...   \n",
      "4582                Zionism   \n",
      "4583              Zirconium   \n",
      "4584              Zoroaster   \n",
      "4585           Zuid-Gelders   \n",
      "4586                   Zulu   \n",
      "\n",
      "                                        common_articles  \\\n",
      "0     ['Orkney', 'Isle_of_Man', 'Monarchy', 'Great_B...   \n",
      "1     ['Time_zone', 'World_War_II', 'Currency', 'Eur...   \n",
      "2     ['Germany', 'United_States_dollar', 'Italy', '...   \n",
      "3     ['English_language', 'Ireland', 'Republic_of_I...   \n",
      "4     ['Lion', 'Great_Britain', 'Ireland', 'Scotland...   \n",
      "...                                                 ...   \n",
      "4582  ['Argentina', 'United_Nations', 'World_War_II'...   \n",
      "4583          ['Steel', 'Electron', 'Bicycle', 'India']   \n",
      "4584                          ['Christianity', 'India']   \n",
      "4585                                                 []   \n",
      "4586               ['Christianity', 'English_language']   \n",
      "\n",
      "                                           common_propn  \n",
      "0                  [Monarchy, Ireland, Scotland, Wales]  \n",
      "1                                                [Euro]  \n",
      "2                              [Germany, Italy, France]  \n",
      "3                                     [Ireland, Canada]  \n",
      "4                    [Lion, Ireland, Scotland, England]  \n",
      "...                                                 ...  \n",
      "4582  [Argentina, Europe, Italy, India, Germany, Jud...  \n",
      "4583                  [Steel, Electron, Bicycle, India]  \n",
      "4584                              [Christianity, India]  \n",
      "4585                                                 []  \n",
      "4586                                     [Christianity]  \n",
      "\n",
      "[4587 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 2nd try\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import ast\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load the data from the CSV file\n",
    "csv_file_path = \"data/links_common.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Function to extract proper nouns from a list of words\n",
    "def extract_proper_nouns(words):\n",
    "    words_list = ast.literal_eval(words)  # Convert string to list\n",
    "    doc = nlp(\" \".join(words_list))\n",
    "    proper_nouns = [token.text for token in doc if token.pos_ == 'PROPN' and token.text.istitle() and token.text.isalpha()]\n",
    "    return proper_nouns\n",
    "\n",
    "# Apply the function to the 'common_articles' column and create a new column 'common_propn'\n",
    "df['common_propn'] = df['common_articles'].apply(extract_proper_nouns)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "new_csv_file_path = \"data/links_common_updated_2.csv\"\n",
    "df.to_csv(new_csv_file_path, index=False)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"\\nUpdated DataFrame:\")\n",
    "print(df[['article', 'common_articles', 'common_propn']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6bc61b-94c1-4e5a-a7ce-c27061fd2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Third try\n",
    "def create_set(link, df):\n",
    "    return set(df[df[\"linkSource\"] == link][\"linkTarget\"].to_numpy())\n",
    "\n",
    "df_links_common = pd.DataFrame(\n",
    "    columns=[\"reference_article\", \"article\", \"common_articles\"]\n",
    ")\n",
    "reference_article = \"United_Kingdom\"\n",
    "\n",
    "reference_set = create_set(reference_article, links)\n",
    "\n",
    "for article_name in links[\"linkSource\"].unique():\n",
    "    comparison_set = create_set(article_name, links)\n",
    "    new_row = {\n",
    "        \"reference_article\": reference_article,\n",
    "        \"article\": article_name,\n",
    "        \"common_articles\": list(reference_set & comparison_set),\n",
    "    }\n",
    "    df_links_common.loc[df_links_common.shape[0]] = new_row\n",
    "\n",
    "write = True\n",
    "if write:\n",
    "    write_to_csv(\"data/links_common.csv\", df_links_common, [\"reference_article\", \"article\", \"common_articles\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f90003-de75-4463-9f89-b139152ed91b",
   "metadata": {},
   "source": [
    "## Find the intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "443a938d-6967-460f-9eea-c08390aa5bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24b72436-d99b-481f-9968-ed85a0852636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file_path_link = \"data/links_common.csv\"\n",
    "df_link = pd.read_csv(csv_file_path_link)\n",
    "\n",
    "csv_file_path_propn = \"data/preprocessed_data.csv\"\n",
    "df_propn = pd.read_csv(csv_file_path_propn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0cae1c3f-e285-49ce-a3b2-ef52e021d0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_propn['Proper_Nouns'] = df_propn['Tokens_POS'].apply(lambda x: [token[0] for token in eval(x) if token[1] == 'PROPN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a33994b-b581-4d06-aa95-71fbe6da585e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_propn.rename(columns={'Article': 'article'}, inplace=True)\n",
    "df_propn['article'] = df_propn['article'].apply(urllib.parse.unquote)\n",
    "df_propn['article'] = df_propn['article'].str.replace('.txt', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4f7fa86d-086b-4b8a-a752-5feeb0f15951",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>Tokens_POS</th>\n",
       "      <th>Proper_Nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>√Åed√°n_mac_Gabr√°in</td>\n",
       "      <td>[('copyright', 'NOUN'), ('√Åed√°n', 'PROPN'), ('...</td>\n",
       "      <td>[√Åed√°n, mac, Gabr√°in, Schools, Wikipedia, Sele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>√Öland</td>\n",
       "      <td>[('copyright', 'NOUN'), ('√Öland', 'PROPN'), ('...</td>\n",
       "      <td>[√Öland, Schools, Wikipedia, Selection, Europea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>√âdouard_Manet</td>\n",
       "      <td>[('copyright', 'NOUN'), ('√âdouard', 'PROPN'), ...</td>\n",
       "      <td>[√âdouard, Manet, Schools, Wikipedia, Selection...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>√âire</td>\n",
       "      <td>[('copyright', 'NOUN'), ('√âire', 'PROPN'), ('S...</td>\n",
       "      <td>[√âire, Schools, Wikipedia, Selection, European...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>√ìengus_I_of_the_Picts</td>\n",
       "      <td>[('copyright', 'NOUN'), ('√ìengus', 'PROPN'), (...</td>\n",
       "      <td>[√ìengus, Picts, Schools, Wikipedia, Selection,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>Zionism</td>\n",
       "      <td>[('copyright', 'NOUN'), ('Zionism', 'PROPN'), ...</td>\n",
       "      <td>[Zionism, Schools, Wikipedia, Selection, State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>Zirconium</td>\n",
       "      <td>[('copyright', 'NOUN'), ('Zirconium', 'PROPN')...</td>\n",
       "      <td>[Zirconium, Schools, Wikipedia, Selection, zir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>Zoroaster</td>\n",
       "      <td>[('copyright', 'NOUN'), ('Zoroaster', 'PROPN')...</td>\n",
       "      <td>[Zoroaster, Schools, Wikipedia, Selection, Zor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>Zuid-Gelders</td>\n",
       "      <td>[('copyright', 'NOUN'), ('Zuid', 'PROPN'), ('G...</td>\n",
       "      <td>[Zuid, Gelders, Schools, Wikipedia, Selection,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>Zulu</td>\n",
       "      <td>[('copyright', 'NOUN'), ('Zulu', 'PROPN'), ('S...</td>\n",
       "      <td>[Zulu, Schools, Wikipedia, Selection, African,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4605 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    article  \\\n",
       "0         √Åed√°n_mac_Gabr√°in   \n",
       "1                     √Öland   \n",
       "2             √âdouard_Manet   \n",
       "3                      √âire   \n",
       "4     √ìengus_I_of_the_Picts   \n",
       "...                     ...   \n",
       "4600                Zionism   \n",
       "4601              Zirconium   \n",
       "4602              Zoroaster   \n",
       "4603           Zuid-Gelders   \n",
       "4604                   Zulu   \n",
       "\n",
       "                                             Tokens_POS  \\\n",
       "0     [('copyright', 'NOUN'), ('√Åed√°n', 'PROPN'), ('...   \n",
       "1     [('copyright', 'NOUN'), ('√Öland', 'PROPN'), ('...   \n",
       "2     [('copyright', 'NOUN'), ('√âdouard', 'PROPN'), ...   \n",
       "3     [('copyright', 'NOUN'), ('√âire', 'PROPN'), ('S...   \n",
       "4     [('copyright', 'NOUN'), ('√ìengus', 'PROPN'), (...   \n",
       "...                                                 ...   \n",
       "4600  [('copyright', 'NOUN'), ('Zionism', 'PROPN'), ...   \n",
       "4601  [('copyright', 'NOUN'), ('Zirconium', 'PROPN')...   \n",
       "4602  [('copyright', 'NOUN'), ('Zoroaster', 'PROPN')...   \n",
       "4603  [('copyright', 'NOUN'), ('Zuid', 'PROPN'), ('G...   \n",
       "4604  [('copyright', 'NOUN'), ('Zulu', 'PROPN'), ('S...   \n",
       "\n",
       "                                           Proper_Nouns  \n",
       "0     [√Åed√°n, mac, Gabr√°in, Schools, Wikipedia, Sele...  \n",
       "1     [√Öland, Schools, Wikipedia, Selection, Europea...  \n",
       "2     [√âdouard, Manet, Schools, Wikipedia, Selection...  \n",
       "3     [√âire, Schools, Wikipedia, Selection, European...  \n",
       "4     [√ìengus, Picts, Schools, Wikipedia, Selection,...  \n",
       "...                                                 ...  \n",
       "4600  [Zionism, Schools, Wikipedia, Selection, State...  \n",
       "4601  [Zirconium, Schools, Wikipedia, Selection, zir...  \n",
       "4602  [Zoroaster, Schools, Wikipedia, Selection, Zor...  \n",
       "4603  [Zuid, Gelders, Schools, Wikipedia, Selection,...  \n",
       "4604  [Zulu, Schools, Wikipedia, Selection, African,...  \n",
       "\n",
       "[4605 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08590c72-c439-4f57-8ead-261041b8f16a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_article</th>\n",
       "      <th>article</th>\n",
       "      <th>common_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>√Åed√°n_mac_Gabr√°in</td>\n",
       "      <td>['Orkney', 'Isle_of_Man', 'Monarchy', 'Great_B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>√Öland</td>\n",
       "      <td>['Time_zone', 'World_War_II', 'Currency', 'Eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>√âdouard_Manet</td>\n",
       "      <td>['Germany', 'United_States_dollar', 'Italy', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>√âire</td>\n",
       "      <td>['English_language', 'Ireland', 'Republic_of_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>√ìengus_I_of_the_Picts</td>\n",
       "      <td>['Lion', 'Great_Britain', 'Ireland', 'Scotland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4582</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zionism</td>\n",
       "      <td>['Argentina', 'United_Nations', 'World_War_II'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4583</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zirconium</td>\n",
       "      <td>['Steel', 'Electron', 'Bicycle', 'India']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zoroaster</td>\n",
       "      <td>['Christianity', 'India']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zuid-Gelders</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zulu</td>\n",
       "      <td>['Christianity', 'English_language']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4587 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     reference_article                article  \\\n",
       "0       United_Kingdom      √Åed√°n_mac_Gabr√°in   \n",
       "1       United_Kingdom                  √Öland   \n",
       "2       United_Kingdom          √âdouard_Manet   \n",
       "3       United_Kingdom                   √âire   \n",
       "4       United_Kingdom  √ìengus_I_of_the_Picts   \n",
       "...                ...                    ...   \n",
       "4582    United_Kingdom                Zionism   \n",
       "4583    United_Kingdom              Zirconium   \n",
       "4584    United_Kingdom              Zoroaster   \n",
       "4585    United_Kingdom           Zuid-Gelders   \n",
       "4586    United_Kingdom                   Zulu   \n",
       "\n",
       "                                        common_articles  \n",
       "0     ['Orkney', 'Isle_of_Man', 'Monarchy', 'Great_B...  \n",
       "1     ['Time_zone', 'World_War_II', 'Currency', 'Eur...  \n",
       "2     ['Germany', 'United_States_dollar', 'Italy', '...  \n",
       "3     ['English_language', 'Ireland', 'Republic_of_I...  \n",
       "4     ['Lion', 'Great_Britain', 'Ireland', 'Scotland...  \n",
       "...                                                 ...  \n",
       "4582  ['Argentina', 'United_Nations', 'World_War_II'...  \n",
       "4583          ['Steel', 'Electron', 'Bicycle', 'India']  \n",
       "4584                          ['Christianity', 'India']  \n",
       "4585                                                 []  \n",
       "4586               ['Christianity', 'English_language']  \n",
       "\n",
       "[4587 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce192dec-cef5-4e3d-a9a4-65b29f2123cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge on the 'article'\n",
    "result_df = pd.merge(df_link, df_propn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3ac14928-cc4f-43c5-b309-85cbf0cb159f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     reference_article                article  \\\n",
      "0       United_Kingdom      √Åed√°n_mac_Gabr√°in   \n",
      "1       United_Kingdom                  √Öland   \n",
      "2       United_Kingdom          √âdouard_Manet   \n",
      "3       United_Kingdom                   √âire   \n",
      "4       United_Kingdom  √ìengus_I_of_the_Picts   \n",
      "...                ...                    ...   \n",
      "4582    United_Kingdom                Zionism   \n",
      "4583    United_Kingdom              Zirconium   \n",
      "4584    United_Kingdom              Zoroaster   \n",
      "4585    United_Kingdom           Zuid-Gelders   \n",
      "4586    United_Kingdom                   Zulu   \n",
      "\n",
      "                                        common_articles  \\\n",
      "0     ['Orkney', 'Isle_of_Man', 'Monarchy', 'Great_B...   \n",
      "1     ['Time_zone', 'World_War_II', 'Currency', 'Eur...   \n",
      "2     ['Germany', 'United_States_dollar', 'Italy', '...   \n",
      "3     ['English_language', 'Ireland', 'Republic_of_I...   \n",
      "4     ['Lion', 'Great_Britain', 'Ireland', 'Scotland...   \n",
      "...                                                 ...   \n",
      "4582  ['Argentina', 'United_Nations', 'World_War_II'...   \n",
      "4583          ['Steel', 'Electron', 'Bicycle', 'India']   \n",
      "4584                          ['Christianity', 'India']   \n",
      "4585                                                 []   \n",
      "4586               ['Christianity', 'English_language']   \n",
      "\n",
      "                                           Proper_Nouns  \n",
      "0     [√Åed√°n, mac, Gabr√°in, Schools, Wikipedia, Sele...  \n",
      "1     [√Öland, Schools, Wikipedia, Selection, Europea...  \n",
      "2     [√âdouard, Manet, Schools, Wikipedia, Selection...  \n",
      "3     [√âire, Schools, Wikipedia, Selection, European...  \n",
      "4     [√ìengus, Picts, Schools, Wikipedia, Selection,...  \n",
      "...                                                 ...  \n",
      "4582  [Zionism, Schools, Wikipedia, Selection, State...  \n",
      "4583  [Zirconium, Schools, Wikipedia, Selection, zir...  \n",
      "4584  [Zoroaster, Schools, Wikipedia, Selection, Zor...  \n",
      "4585  [Zuid, Gelders, Schools, Wikipedia, Selection,...  \n",
      "4586  [Zulu, Schools, Wikipedia, Selection, African,...  \n",
      "\n",
      "[4587 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result_df[['reference_article', 'article', 'common_articles', 'Proper_Nouns']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de6acdc1-a0d3-4d94-ab99-2e2430f052ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result_df['Proper_Nouns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "899a9f11-e62f-4780-be0c-04b63e51e124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#result_df['Proper_Nouns'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e7cc8b8a-b6c4-4969-a255-77f61aa5b34f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df['common_articles'] = result_df['common_articles'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "498373c4-db2d-4785-83a0-c9634c7ff41b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result_df[\"common_articles\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "63530c68-e94a-494a-9475-79d4fc3b8f47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = result_df[\"common_articles\"][0]\n",
    "y = result_df[\"Proper_Nouns\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "497c27d1-9d29-4d0e-87d9-c5a040efb10d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ireland', 'Orkney', 'Scotland'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = set(x).intersection(y)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "53260e12-5159-454c-af10-d076ed88b38b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 4587)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5afd760b-a2a7-4ed7-9e96-558b80559f30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annad\\AppData\\Local\\Temp\\ipykernel_13820\\2152290474.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_df[\"intersection\"][i] = set(x).intersection(y)\n",
      "C:\\Users\\annad\\AppData\\Local\\Temp\\ipykernel_13820\\2152290474.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '{'Scotland', 'Ireland', 'Orkney'}' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  result_df[\"intersection\"][i] = set(x).intersection(y)\n"
     ]
    }
   ],
   "source": [
    "result_df['intersection'] = np.nan\n",
    "\n",
    "for i in range(len(result_df)):\n",
    "    x = result_df[\"common_articles\"][i]\n",
    "    y = result_df[\"Proper_Nouns\"][i]\n",
    "    result_df[\"intersection\"][i] = set(x).intersection(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "beb489bd-44b3-4c5b-a381-3253dc3c126c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_article</th>\n",
       "      <th>article</th>\n",
       "      <th>common_articles</th>\n",
       "      <th>Tokens_POS</th>\n",
       "      <th>Proper_Nouns</th>\n",
       "      <th>intersection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>√Åed√°n_mac_Gabr√°in</td>\n",
       "      <td>[Orkney, Isle_of_Man, Monarchy, Great_Britain,...</td>\n",
       "      <td>[('copyright', 'NOUN'), ('√Åed√°n', 'PROPN'), ('...</td>\n",
       "      <td>[√Åed√°n, mac, Gabr√°in, Schools, Wikipedia, Sele...</td>\n",
       "      <td>{Scotland, Ireland, Orkney}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>√Öland</td>\n",
       "      <td>[Time_zone, World_War_II, Currency, European_U...</td>\n",
       "      <td>[('copyright', 'NOUN'), ('√Öland', 'PROPN'), ('...</td>\n",
       "      <td>[√Öland, Schools, Wikipedia, Selection, Europea...</td>\n",
       "      <td>{Currency, Euro}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>√âdouard_Manet</td>\n",
       "      <td>[Germany, United_States_dollar, Italy, France]</td>\n",
       "      <td>[('copyright', 'NOUN'), ('√âdouard', 'PROPN'), ...</td>\n",
       "      <td>[√âdouard, Manet, Schools, Wikipedia, Selection...</td>\n",
       "      <td>{Italy, Germany, France}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>√âire</td>\n",
       "      <td>[English_language, Ireland, Republic_of_Irelan...</td>\n",
       "      <td>[('copyright', 'NOUN'), ('√âire', 'PROPN'), ('S...</td>\n",
       "      <td>[√âire, Schools, Wikipedia, Selection, European...</td>\n",
       "      <td>{Canada, Ireland}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>√ìengus_I_of_the_Picts</td>\n",
       "      <td>[Lion, Great_Britain, Ireland, Scotland, England]</td>\n",
       "      <td>[('copyright', 'NOUN'), ('√ìengus', 'PROPN'), (...</td>\n",
       "      <td>[√ìengus, Picts, Schools, Wikipedia, Selection,...</td>\n",
       "      <td>{Scotland, England, Ireland}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4582</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zionism</td>\n",
       "      <td>[Argentina, United_Nations, World_War_II, Euro...</td>\n",
       "      <td>[('copyright', 'NOUN'), ('Zionism', 'PROPN'), ...</td>\n",
       "      <td>[Zionism, Schools, Wikipedia, Selection, State...</td>\n",
       "      <td>{Argentina, France, Europe, Judaism, India, Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4583</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zirconium</td>\n",
       "      <td>[Steel, Electron, Bicycle, India]</td>\n",
       "      <td>[('copyright', 'NOUN'), ('Zirconium', 'PROPN')...</td>\n",
       "      <td>[Zirconium, Schools, Wikipedia, Selection, zir...</td>\n",
       "      <td>{India, Electron}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zoroaster</td>\n",
       "      <td>[Christianity, India]</td>\n",
       "      <td>[('copyright', 'NOUN'), ('Zoroaster', 'PROPN')...</td>\n",
       "      <td>[Zoroaster, Schools, Wikipedia, Selection, Zor...</td>\n",
       "      <td>{India, Christianity}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zuid-Gelders</td>\n",
       "      <td>[]</td>\n",
       "      <td>[('copyright', 'NOUN'), ('Zuid', 'PROPN'), ('G...</td>\n",
       "      <td>[Zuid, Gelders, Schools, Wikipedia, Selection,...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zulu</td>\n",
       "      <td>[Christianity, English_language]</td>\n",
       "      <td>[('copyright', 'NOUN'), ('Zulu', 'PROPN'), ('S...</td>\n",
       "      <td>[Zulu, Schools, Wikipedia, Selection, African,...</td>\n",
       "      <td>{Christianity}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4587 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     reference_article                article  \\\n",
       "0       United_Kingdom      √Åed√°n_mac_Gabr√°in   \n",
       "1       United_Kingdom                  √Öland   \n",
       "2       United_Kingdom          √âdouard_Manet   \n",
       "3       United_Kingdom                   √âire   \n",
       "4       United_Kingdom  √ìengus_I_of_the_Picts   \n",
       "...                ...                    ...   \n",
       "4582    United_Kingdom                Zionism   \n",
       "4583    United_Kingdom              Zirconium   \n",
       "4584    United_Kingdom              Zoroaster   \n",
       "4585    United_Kingdom           Zuid-Gelders   \n",
       "4586    United_Kingdom                   Zulu   \n",
       "\n",
       "                                        common_articles  \\\n",
       "0     [Orkney, Isle_of_Man, Monarchy, Great_Britain,...   \n",
       "1     [Time_zone, World_War_II, Currency, European_U...   \n",
       "2        [Germany, United_States_dollar, Italy, France]   \n",
       "3     [English_language, Ireland, Republic_of_Irelan...   \n",
       "4     [Lion, Great_Britain, Ireland, Scotland, England]   \n",
       "...                                                 ...   \n",
       "4582  [Argentina, United_Nations, World_War_II, Euro...   \n",
       "4583                  [Steel, Electron, Bicycle, India]   \n",
       "4584                              [Christianity, India]   \n",
       "4585                                                 []   \n",
       "4586                   [Christianity, English_language]   \n",
       "\n",
       "                                             Tokens_POS  \\\n",
       "0     [('copyright', 'NOUN'), ('√Åed√°n', 'PROPN'), ('...   \n",
       "1     [('copyright', 'NOUN'), ('√Öland', 'PROPN'), ('...   \n",
       "2     [('copyright', 'NOUN'), ('√âdouard', 'PROPN'), ...   \n",
       "3     [('copyright', 'NOUN'), ('√âire', 'PROPN'), ('S...   \n",
       "4     [('copyright', 'NOUN'), ('√ìengus', 'PROPN'), (...   \n",
       "...                                                 ...   \n",
       "4582  [('copyright', 'NOUN'), ('Zionism', 'PROPN'), ...   \n",
       "4583  [('copyright', 'NOUN'), ('Zirconium', 'PROPN')...   \n",
       "4584  [('copyright', 'NOUN'), ('Zoroaster', 'PROPN')...   \n",
       "4585  [('copyright', 'NOUN'), ('Zuid', 'PROPN'), ('G...   \n",
       "4586  [('copyright', 'NOUN'), ('Zulu', 'PROPN'), ('S...   \n",
       "\n",
       "                                           Proper_Nouns  \\\n",
       "0     [√Åed√°n, mac, Gabr√°in, Schools, Wikipedia, Sele...   \n",
       "1     [√Öland, Schools, Wikipedia, Selection, Europea...   \n",
       "2     [√âdouard, Manet, Schools, Wikipedia, Selection...   \n",
       "3     [√âire, Schools, Wikipedia, Selection, European...   \n",
       "4     [√ìengus, Picts, Schools, Wikipedia, Selection,...   \n",
       "...                                                 ...   \n",
       "4582  [Zionism, Schools, Wikipedia, Selection, State...   \n",
       "4583  [Zirconium, Schools, Wikipedia, Selection, zir...   \n",
       "4584  [Zoroaster, Schools, Wikipedia, Selection, Zor...   \n",
       "4585  [Zuid, Gelders, Schools, Wikipedia, Selection,...   \n",
       "4586  [Zulu, Schools, Wikipedia, Selection, African,...   \n",
       "\n",
       "                                           intersection  \n",
       "0                           {Scotland, Ireland, Orkney}  \n",
       "1                                      {Currency, Euro}  \n",
       "2                              {Italy, Germany, France}  \n",
       "3                                     {Canada, Ireland}  \n",
       "4                          {Scotland, England, Ireland}  \n",
       "...                                                 ...  \n",
       "4582  {Argentina, France, Europe, Judaism, India, Ge...  \n",
       "4583                                  {India, Electron}  \n",
       "4584                              {India, Christianity}  \n",
       "4585                                                 {}  \n",
       "4586                                     {Christianity}  \n",
       "\n",
       "[4587 rows x 6 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6dd23a6f-78ce-4260-87f7-7066b456edc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df[[\"reference_article\", \"article\", \"intersection\"]].to_csv(\"data/intersect_link_propn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9d29a8bd-d3ea-43bc-9b5d-3752c1fe5ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df.to_csv(\"data/merged_link_propn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc4e55-1bdd-4465-a514-ba91b1b0627d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
