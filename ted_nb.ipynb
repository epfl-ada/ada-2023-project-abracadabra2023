{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import csv\n",
    "from ast import literal_eval\n",
    "\n",
    "import spacy\n",
    "from empath import Empath\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, PlaintextCorpusReader\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "from cliches import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_uk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_uk\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mtolist() \n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_uk' is not defined"
     ]
    }
   ],
   "source": [
    "df_uk[\"attribute\"].to_numpy().tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributes of UK:\n",
      "  arrogant arrogant domineer cowardly bad teeth snob conceited snooty bad teeth snobby uncontrolled cold stiff upper lip aristocratic pompous refine tea drinking annoyed tea country theory good swimmer uncertain stiff upper lip good making tea british pompous understated tea queen stuck multiracial stuffy vapid labour trendy fantastic chess fussy multifaith genero self deprecate sophisticated sophisticated stiff imperialist stiff self indulgent proper superior direct proper love tea civilize forward elegant drink tea culture reserve polite good cricket fair intelligent practical brave red word aloof cat parochial generous polite drink tea intelligent love tea superior refine witty hardworking tasteful civilize progress self control reserve unyielding fair honourable practical shy clever bore aloof considerate brave sociable progressive generous warmth courageous expect kind art travel eat lot colour bought outgo affectionate\n",
      "\n",
      "main topics:\n",
      "liquid               7.874%\n",
      "body                 4.724%\n",
      "dominant_personality 4.724%\n",
      "emotional            3.937%\n",
      "strength             3.937%\n",
      "heroic               3.150%\n",
      "appearance           3.150%\n",
      "wealthy              2.362%\n",
      "optimism             2.362%\n",
      "hipster              2.362%\n"
     ]
    }
   ],
   "source": [
    "# load seegull data\n",
    "df_cliches = pd.read_csv(\"data/seegull.csv\")\n",
    "# extract attributes related to British and English\n",
    "df_uk = df_cliches[np.isin(df_cliches[\"identity\"], [\"British\", \"English\"])]\n",
    "attributes_uk = df_uk[\"attribute\"].to_numpy().tolist()\n",
    "# remove all stopwords\n",
    "new = []\n",
    "english_stopwords = stopwords.words(\"english\")\n",
    "for a in attributes_uk:\n",
    "    new.extend([word for word in a.split(\" \") if word not in english_stopwords])\n",
    "joined_attributes_uk = \" \".join(new)\n",
    "print(\"attributes of UK:\\n \", joined_attributes_uk)\n",
    "# find main topics \n",
    "print(\"\\nmain topics:\")\n",
    "top_10 = top_k_categories(joined_attributes_uk, 10, True)\n",
    "uk_topics_seegull = [t[0] for t in top_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the keys in the column \"article_name\" by removing the suffix \".txt\"\n",
    "# topics_file = \"data/topics_articles.csv\"\n",
    "# article_topics = pd.read_csv(topics_file)\n",
    "# np.set_printoptions(linewidth=100000)\n",
    "# article_topics[\"article_name\"] = article_topics[\"article_name\"].str.replace(\".txt\", \"\")\n",
    "# article_topics.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "# article_topics.to_csv(topics_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_name</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>%C3%81ed%C3%A1n_mac_Gabr%C3%A1in</td>\n",
       "      <td>[wedding, family, royalty, medieval, death, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>%C3%85land</td>\n",
       "      <td>[beach, water, exotic, sailing, ocean, help, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>%C3%89douard_Manet</td>\n",
       "      <td>[art, appearance, fashion, beauty, feminine, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>%C3%89ire</td>\n",
       "      <td>[government, help, office, dance, money, weddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>%C3%93engus_I_of_the_Picts</td>\n",
       "      <td>[wedding, family, royalty, medieval, death, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>Zionism</td>\n",
       "      <td>[help, office, dance, money, wedding, domestic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>Zirconium</td>\n",
       "      <td>[tool, breaking, help, office, dance, money, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>Zoroaster</td>\n",
       "      <td>[celebration, ancient, meeting, party, help, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>Zuid-Gelders</td>\n",
       "      <td>[speaking, hearing, shape_and_size, help, offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>Zulu</td>\n",
       "      <td>[leader, military, order, speaking, white_coll...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4604 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          article_name  \\\n",
       "0     %C3%81ed%C3%A1n_mac_Gabr%C3%A1in   \n",
       "1                           %C3%85land   \n",
       "2                   %C3%89douard_Manet   \n",
       "3                            %C3%89ire   \n",
       "4           %C3%93engus_I_of_the_Picts   \n",
       "...                                ...   \n",
       "4599                           Zionism   \n",
       "4600                         Zirconium   \n",
       "4601                         Zoroaster   \n",
       "4602                      Zuid-Gelders   \n",
       "4603                              Zulu   \n",
       "\n",
       "                                                 topics  \n",
       "0     [wedding, family, royalty, medieval, death, he...  \n",
       "1     [beach, water, exotic, sailing, ocean, help, o...  \n",
       "2     [art, appearance, fashion, beauty, feminine, c...  \n",
       "3     [government, help, office, dance, money, weddi...  \n",
       "4     [wedding, family, royalty, medieval, death, yo...  \n",
       "...                                                 ...  \n",
       "4599  [help, office, dance, money, wedding, domestic...  \n",
       "4600  [tool, breaking, help, office, dance, money, w...  \n",
       "4601  [celebration, ancient, meeting, party, help, o...  \n",
       "4602  [speaking, hearing, shape_and_size, help, offi...  \n",
       "4603  [leader, military, order, speaking, white_coll...  \n",
       "\n",
       "[4604 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# topics in each article\n",
    "topics_file = \"data/topics_articles.csv\"\n",
    "article_topics = pd.read_csv(\n",
    "    topics_file,\n",
    "    usecols=[\"article_name\", \"topics\"],\n",
    "    converters={\n",
    "        \"topics\": (lambda s: literal_eval(\"[\" + (\",\".join(s[1:-1].split(\" \"))) + \"]\"))\n",
    "    },\n",
    ")\n",
    "display(article_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 comparisons with most common topics:\n",
      "%C3%85land and United Kingdom: {'help', 'office', 'beach', 'wedding', 'sailing', 'ocean', 'water', 'dance', 'money', 'exotic'}\n",
      "Achilles and United Kingdom: {'help', 'office', 'beach', 'wedding', 'sailing', 'ocean', 'water', 'dance', 'money', 'exotic'}\n",
      "Alfred_the_Great and United Kingdom: {'royalty', 'help', 'office', 'wedding', 'medieval', 'positive_emotion', 'achievement', 'power', 'dance', 'money'}\n",
      "American_Samoa and United Kingdom: {'help', 'office', 'beach', 'wedding', 'sailing', 'ocean', 'water', 'dance', 'money', 'exotic'}\n",
      "Antigua_and_Barbuda and United Kingdom: {'help', 'office', 'beach', 'wedding', 'sailing', 'ocean', 'water', 'dance', 'money', 'exotic'}\n"
     ]
    }
   ],
   "source": [
    "# United Kingdom topics\n",
    "uk_topics = (\n",
    "    article_topics[article_topics[\"article_name\"] == \"United_Kingdom\"][\"topics\"].values[\n",
    "        0\n",
    "    ]\n",
    "    + article_topics[article_topics[\"article_name\"] == \"England\"][\"topics\"].values[0]\n",
    "    + article_topics[article_topics[\"article_name\"] == \"Great_Britain\"][\"topics\"].values[0]\n",
    "    + uk_topics_seegull\n",
    ")\n",
    "\n",
    "\n",
    "# Function to extract common topcis\n",
    "def extract_common(topics_str1: str, topics_str2: str) -> set:\n",
    "    return set(topics_str1) & set(topics_str2)\n",
    "\n",
    "\n",
    "# Compare topics for all articles in the dataset\n",
    "articles_with_common_topics = []\n",
    "for index, row in article_topics.iterrows():\n",
    "    if row[\"article_name\"] not in {\"United_Kingdom\", \"England\"}:\n",
    "        common_topics = extract_common(row[\"topics\"], uk_topics)\n",
    "        if len(common_topics) > 0:\n",
    "            articles_with_common_topics.append(\n",
    "                {\"article_name\": row[\"article_name\"], \"common_topics\": common_topics}\n",
    "            )\n",
    "\n",
    "# Sort comparisons based on the number of common topics\n",
    "articles_with_common_topics.sort(key=lambda x: len(x[\"common_topics\"]), reverse=True)\n",
    "\n",
    "# Print the top 5 comparisons\n",
    "print(\"Top 5 comparisons with most common topics:\")\n",
    "for i in range(min(5, len(articles_with_common_topics))):\n",
    "    print(\n",
    "        f\"{articles_with_common_topics[i]['article_name']} and United Kingdom: {articles_with_common_topics[i]['common_topics']}\"\n",
    "    )\n",
    "\n",
    "# Save the top 50 comparisons to a CSV file\n",
    "top_articles_in_common_topics = pd.DataFrame(articles_with_common_topics)\n",
    "top_articles_in_common_topics.to_csv(\"data/ted_top_topic_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOms propres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_and_pos = pd.read_csv(\"data/preprocessed_data.csv\")\n",
    "tokens_and_pos[\"Article\"] = tokens_and_pos[\"Article\"].str.replace(\".txt\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 comparisons with most common proper nouns:\n",
      "United_Kingdom_national_football_team and United_Kingdom: {'Ireland', 'UK', 'Kingdom', 'Scotland', 'Northern', 'United', 'England'}\n",
      "Pound_sterling and United_Kingdom: {'Ireland', 'UK', 'Kingdom', 'Scotland', 'Northern', 'United', 'England'}\n",
      "Great_Britain and United_Kingdom: {'Ireland', 'Kingdom', 'Scotland', 'Northern', 'United', 'England', 'British'}\n",
      "England and United_Kingdom: {'London', 'UK', 'Kingdom', 'Scotland', 'United', 'England'}\n",
      "British_Isles and United_Kingdom: {'Ireland', 'Kingdom', 'Scotland', 'United', 'England', 'British'}\n",
      "Top comparisons with most common proper nouns saved to data/top_proper_noun_comparisons.csv\n"
     ]
    }
   ],
   "source": [
    "# Replace 'United_Kingdom.txt' with the target article name\n",
    "target_article_name = 'United_Kingdom'\n",
    "\n",
    "# Filter rows related to the target article\n",
    "target_article_data = tokens_and_pos[tokens_and_pos['Article'] == target_article_name]\n",
    "\n",
    "# Check if the target article is present in the DataFrame\n",
    "if not target_article_data.empty:\n",
    "    # Extract the top 10 PROPN tokens for the target article\n",
    "    target_proper_nouns = [token[0] for tokens_pos_list in target_article_data['Tokens_POS'] for token in eval(tokens_pos_list) if token[1] == 'PROPN']\n",
    "    top_target_proper_nouns = [item[0] for item in Counter(target_proper_nouns).most_common(10)]\n",
    "\n",
    "    # Initialize a list to store common proper nouns\n",
    "    common_proper_nouns = []\n",
    "\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in tokens_and_pos.iterrows():\n",
    "        if row['Article'] == target_article_name:\n",
    "            continue\n",
    "        # Extract the top 10 PROPN tokens for each article\n",
    "        article_proper_nouns = [token[0] for token in eval(row['Tokens_POS']) if token[1] == 'PROPN']\n",
    "        top_article_proper_nouns = [item[0] for item in Counter(article_proper_nouns).most_common(10)]\n",
    "\n",
    "        # Compare with the top PROPN tokens of the target article\n",
    "        common_tokens = set(top_article_proper_nouns) & set(top_target_proper_nouns)\n",
    "\n",
    "        # Store the results\n",
    "        common_proper_nouns.append({'Article': row['Article'], 'Common_Propnouns': common_tokens})\n",
    "\n",
    "    # Convert the results to a DataFrame\n",
    "    common_proper_nouns_df = pd.DataFrame(common_proper_nouns)\n",
    "\n",
    "    # Sort the DataFrame based on the number of common proper nouns\n",
    "    common_proper_nouns_df = common_proper_nouns_df.sort_values(by='Common_Propnouns', key=lambda x: x.str.len(), ascending=False)\n",
    "\n",
    "    # Print the top 5 comparisons\n",
    "    print(\"Top 5 comparisons with most common proper nouns:\")\n",
    "    for i in range(min(5, len(common_proper_nouns_df))):\n",
    "        print(f\"{common_proper_nouns_df.iloc[i]['Article']} and {target_article_name}: {common_proper_nouns_df.iloc[i]['Common_Propnouns']}\")\n",
    "\n",
    "    # Save the top comparisons to a CSV file\n",
    "    top_comparisons = common_proper_nouns_df.head(50)\n",
    "    if not top_comparisons.empty:\n",
    "        top_comparisons.to_csv(\"data/top_proper_noun_comparisons.csv\", index=False)\n",
    "        print(\"Top comparisons with most common proper nouns saved to data/top_proper_noun_comparisons.csv\")\n",
    "    else:\n",
    "        print(\"No common proper nouns found.\")\n",
    "else:\n",
    "    print(f\"{target_article_name} not found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import import_and_clean_data\n",
    "(\n",
    "    articles,\n",
    "    categories,\n",
    "    links,\n",
    "    paths_finished,\n",
    "    paths_unfinished,\n",
    ") = import_and_clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set(link, df):\n",
    "    return set(df[df[\"linkSource\"] == link][\"linkTarget\"].to_numpy())\n",
    "\n",
    "# reference article\n",
    "set1 = create_set(\"United_Kingdom\", links)\n",
    "\n",
    "# related article (\"cliché\")\n",
    "set2 = create_set(\"William_IV_of_the_United_Kingdom\", links)\n",
    "\n",
    "# unrelated articles\n",
    "set3 = create_set(\"Zulu\", links)\n",
    "set4 = create_set(\"World_Bank_Group\", links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_article</th>\n",
       "      <th>article</th>\n",
       "      <th>common_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Áedán_mac_Gabráin</td>\n",
       "      <td>['Orkney', 'Isle_of_Man', 'Monarchy', 'Great_B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Åland</td>\n",
       "      <td>['Time_zone', 'World_War_II', 'Currency', 'Eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Édouard_Manet</td>\n",
       "      <td>['Germany', 'United_States_dollar', 'Italy', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Éire</td>\n",
       "      <td>['English_language', 'Ireland', 'Republic_of_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Óengus_I_of_the_Picts</td>\n",
       "      <td>['Lion', 'Great_Britain', 'Ireland', 'Scotland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9169</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zionism</td>\n",
       "      <td>['Argentina', 'Germany', 'United_Nations', 'Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9170</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zirconium</td>\n",
       "      <td>['India', 'Bicycle', 'Electron', 'Steel']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zoroaster</td>\n",
       "      <td>['India', 'Christianity']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9172</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zuid-Gelders</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9173</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Zulu</td>\n",
       "      <td>['English_language', 'Christianity']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9174 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     reference_article                article  \\\n",
       "0       United_Kingdom      Áedán_mac_Gabráin   \n",
       "1       United_Kingdom                  Åland   \n",
       "2       United_Kingdom          Édouard_Manet   \n",
       "3       United_Kingdom                   Éire   \n",
       "4       United_Kingdom  Óengus_I_of_the_Picts   \n",
       "...                ...                    ...   \n",
       "9169    United_Kingdom                Zionism   \n",
       "9170    United_Kingdom              Zirconium   \n",
       "9171    United_Kingdom              Zoroaster   \n",
       "9172    United_Kingdom           Zuid-Gelders   \n",
       "9173    United_Kingdom                   Zulu   \n",
       "\n",
       "                                        common_articles  \n",
       "0     ['Orkney', 'Isle_of_Man', 'Monarchy', 'Great_B...  \n",
       "1     ['Time_zone', 'World_War_II', 'Currency', 'Eur...  \n",
       "2     ['Germany', 'United_States_dollar', 'Italy', '...  \n",
       "3     ['English_language', 'Ireland', 'Republic_of_I...  \n",
       "4     ['Lion', 'Great_Britain', 'Ireland', 'Scotland...  \n",
       "...                                                 ...  \n",
       "9169  ['Argentina', 'Germany', 'United_Nations', 'Br...  \n",
       "9170          ['India', 'Bicycle', 'Electron', 'Steel']  \n",
       "9171                          ['India', 'Christianity']  \n",
       "9172                                                 []  \n",
       "9173               ['English_language', 'Christianity']  \n",
       "\n",
       "[9174 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def write_to_csv(data_path_article, df, columns, header=True, index=False):\n",
    "    if os.path.isfile(data_path_article):\n",
    "        with open(data_path_article, \"a\") as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "\n",
    "            csvwriter.writerows(df.to_numpy())\n",
    "    else:\n",
    "        df.to_csv(\n",
    "            data_path_article,\n",
    "            sep=\",\",\n",
    "            encoding=\"utf-8\",\n",
    "            columns=columns,\n",
    "            header=header,\n",
    "            index=index,\n",
    "        )\n",
    "\n",
    "# create dataframe that contains the links in common between the reference article and an article\n",
    "# done on all the articles\n",
    "# /!\\ dataset is stored in \"links_common.csv\" file\n",
    "df_links_common = pd.DataFrame(\n",
    "    columns=[\"reference_article\", \"article\", \"common_articles\"]\n",
    ")\n",
    "reference_article = \"United_Kingdom\"\n",
    "\n",
    "reference_set = create_set(reference_article, links)\n",
    "\n",
    "for article_name in links[\"linkSource\"].unique():\n",
    "    comparison_set = create_set(article_name, links)\n",
    "    new_row = {\n",
    "        \"reference_article\": reference_article,\n",
    "        \"article\": article_name,\n",
    "        \"common_articles\": list(reference_set & comparison_set),\n",
    "    }\n",
    "    df_links_common.loc[df_links_common.shape[0]] = new_row\n",
    "\n",
    "write = True\n",
    "if write:\n",
    "    write_to_csv(\"data/links_common.csv\", df_links_common, [\"reference_article\", \"article\", \"common_articles\"])\n",
    "\n",
    "common_links_reference = pd.read_csv(\"data/links_common.csv\", encoding=\"utf-8\")\n",
    "common_links_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_article</th>\n",
       "      <th>article</th>\n",
       "      <th>common_articles</th>\n",
       "      <th>nbr_common_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8866</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>['Anglican_Communion', 'Bicycle', 'Ireland', '...</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>['Natural_gas', 'Arctic_Monkeys', 'Novel', 'Qu...</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>England</td>\n",
       "      <td>['French_language', 'Scots_language', 'London'...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>England</td>\n",
       "      <td>['Industrial_Revolution', 'Benjamin_Britten', ...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3642</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>['Industrial_Revolution', 'Parliament_of_the_U...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8229</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>['French_language', 'Scots_language', 'London'...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>United_States</td>\n",
       "      <td>['Natural_gas', 'World_War_II', 'NATO', 'World...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8870</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>United_States</td>\n",
       "      <td>['Computer', 'French_language', 'Jersey', 'NAT...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>British_monarchy</td>\n",
       "      <td>['French_language', 'Anglican_Communion', 'Ire...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>British_monarchy</td>\n",
       "      <td>['Parliament_of_the_United_Kingdom', 'World_Wa...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>['Parliament_of_the_United_Kingdom', 'World_Wa...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7117</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>['The_Rolling_Stones', 'Christianity', 'Europe...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Elizabeth_II_of_the_United_Kingdom</td>\n",
       "      <td>['French_language', 'London', 'Christianity', ...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>British_Isles_(terminology)</td>\n",
       "      <td>['French_language', 'Jersey', 'Ireland', 'Brit...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Europe</td>\n",
       "      <td>['Industrial_Revolution', 'World_War_II', 'NAT...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6014</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Europe</td>\n",
       "      <td>['French_language', 'Jersey', 'London', 'Irela...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>British_Isles_(terminology)</td>\n",
       "      <td>['Scottish_Gaelic_language', 'Northern_Ireland...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Elizabeth_II_of_the_United_Kingdom</td>\n",
       "      <td>['British_monarchy', 'World_War_II', 'Northern...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>English_language</td>\n",
       "      <td>['World_War_II', 'Northern_Ireland', 'Jersey',...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>English_language</td>\n",
       "      <td>['French_language', 'Jersey', 'Scots_language'...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6275</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Germany</td>\n",
       "      <td>['French_language', 'London', 'NATO', 'United_...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>British_Empire</td>\n",
       "      <td>['London', 'British_Isles', 'Henry_VIII_of_Eng...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Wales</td>\n",
       "      <td>['Parliament_of_the_United_Kingdom', 'British_...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>British_Empire</td>\n",
       "      <td>['Industrial_Revolution', 'World_War_II', 'Eng...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Germany</td>\n",
       "      <td>['Natural_gas', 'Industrial_Revolution', 'Worl...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6020</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>European_Union</td>\n",
       "      <td>['French_language', 'London', 'NATO', 'United_...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>European_Union</td>\n",
       "      <td>['Natural_gas', 'World_War_II', 'NATO', 'Engli...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8968</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Wales</td>\n",
       "      <td>['Anglican_Communion', 'Ireland', 'Formula_One...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>['Industrial_Revolution', 'World_War_II', 'Wor...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>British_Isles</td>\n",
       "      <td>['Northern_Ireland', 'Irish_Sea', 'Atlantic_Oc...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5284</th>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>British_Isles</td>\n",
       "      <td>['Jersey', 'London', 'Ireland', 'Republic_of_I...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     reference_article                             article  \\\n",
       "8866    United_Kingdom                      United_Kingdom   \n",
       "4279    United_Kingdom                      United_Kingdom   \n",
       "5966    United_Kingdom                             England   \n",
       "1379    United_Kingdom                             England   \n",
       "3642    United_Kingdom                            Scotland   \n",
       "8229    United_Kingdom                            Scotland   \n",
       "4283    United_Kingdom                       United_States   \n",
       "8870    United_Kingdom                       United_States   \n",
       "5287    United_Kingdom                    British_monarchy   \n",
       "700     United_Kingdom                    British_monarchy   \n",
       "2530    United_Kingdom                              London   \n",
       "7117    United_Kingdom                              London   \n",
       "5947    United_Kingdom  Elizabeth_II_of_the_United_Kingdom   \n",
       "5285    United_Kingdom         British_Isles_(terminology)   \n",
       "1427    United_Kingdom                              Europe   \n",
       "6014    United_Kingdom                              Europe   \n",
       "698     United_Kingdom         British_Isles_(terminology)   \n",
       "1360    United_Kingdom  Elizabeth_II_of_the_United_Kingdom   \n",
       "1383    United_Kingdom                    English_language   \n",
       "5970    United_Kingdom                    English_language   \n",
       "6275    United_Kingdom                             Germany   \n",
       "5280    United_Kingdom                      British_Empire   \n",
       "4381    United_Kingdom                               Wales   \n",
       "693     United_Kingdom                      British_Empire   \n",
       "1688    United_Kingdom                             Germany   \n",
       "6020    United_Kingdom                      European_Union   \n",
       "1433    United_Kingdom                      European_Union   \n",
       "8968    United_Kingdom                               Wales   \n",
       "2622    United_Kingdom                          Manchester   \n",
       "697     United_Kingdom                       British_Isles   \n",
       "5284    United_Kingdom                       British_Isles   \n",
       "\n",
       "                                        common_articles  nbr_common_articles  \n",
       "8866  ['Anglican_Communion', 'Bicycle', 'Ireland', '...                  168  \n",
       "4279  ['Natural_gas', 'Arctic_Monkeys', 'Novel', 'Qu...                  168  \n",
       "5966  ['French_language', 'Scots_language', 'London'...                   63  \n",
       "1379  ['Industrial_Revolution', 'Benjamin_Britten', ...                   63  \n",
       "3642  ['Industrial_Revolution', 'Parliament_of_the_U...                   57  \n",
       "8229  ['French_language', 'Scots_language', 'London'...                   57  \n",
       "4283  ['Natural_gas', 'World_War_II', 'NATO', 'World...                   42  \n",
       "8870  ['Computer', 'French_language', 'Jersey', 'NAT...                   42  \n",
       "5287  ['French_language', 'Anglican_Communion', 'Ire...                   35  \n",
       "700   ['Parliament_of_the_United_Kingdom', 'World_Wa...                   35  \n",
       "2530  ['Parliament_of_the_United_Kingdom', 'World_Wa...                   33  \n",
       "7117  ['The_Rolling_Stones', 'Christianity', 'Europe...                   33  \n",
       "5947  ['French_language', 'London', 'Christianity', ...                   32  \n",
       "5285  ['French_language', 'Jersey', 'Ireland', 'Brit...                   32  \n",
       "1427  ['Industrial_Revolution', 'World_War_II', 'NAT...                   32  \n",
       "6014  ['French_language', 'Jersey', 'London', 'Irela...                   32  \n",
       "698   ['Scottish_Gaelic_language', 'Northern_Ireland...                   32  \n",
       "1360  ['British_monarchy', 'World_War_II', 'Northern...                   32  \n",
       "1383  ['World_War_II', 'Northern_Ireland', 'Jersey',...                   30  \n",
       "5970  ['French_language', 'Jersey', 'Scots_language'...                   30  \n",
       "6275  ['French_language', 'London', 'NATO', 'United_...                   29  \n",
       "5280  ['London', 'British_Isles', 'Henry_VIII_of_Eng...                   29  \n",
       "4381  ['Parliament_of_the_United_Kingdom', 'British_...                   29  \n",
       "693   ['Industrial_Revolution', 'World_War_II', 'Eng...                   29  \n",
       "1688  ['Natural_gas', 'Industrial_Revolution', 'Worl...                   29  \n",
       "6020  ['French_language', 'London', 'NATO', 'United_...                   29  \n",
       "1433  ['Natural_gas', 'World_War_II', 'NATO', 'Engli...                   29  \n",
       "8968  ['Anglican_Communion', 'Ireland', 'Formula_One...                   29  \n",
       "2622  ['Industrial_Revolution', 'World_War_II', 'Wor...                   28  \n",
       "697   ['Northern_Ireland', 'Irish_Sea', 'Atlantic_Oc...                   28  \n",
       "5284  ['Jersey', 'London', 'Ireland', 'Republic_of_I...                   28  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# forgotten cliche: Driving_on_the_left_or_right\n",
    "\n",
    "article_topics = pd.read_csv(\n",
    "    \"data/links_common.csv\",\n",
    "    usecols=[\"article_name\", \"topics\"],\n",
    "    converters={\n",
    "        \"topics\": (lambda s: literal_eval(\"[\" + (\",\".join(s[1:-1].split(\" \"))) + \"]\"))\n",
    "    },\n",
    ")\n",
    "\n",
    "# get most in common links\n",
    "common_links_reference[\"nbr_common_articles\"] = common_links_reference[\"common_articles\"].apply(lambda common_articles: len(ast.literal_eval(common_articles)))\n",
    "common_links_reference.sort_values(\"nbr_common_articles\", ascending=False)[:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
