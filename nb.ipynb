{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "For this second milestone in the project, we're going to perform the following preliminary tasks to evaluate the feasibility of our project:\n",
    "- [x] Load and pre-process the data\n",
    "- [x] Exploratory data analysis to confirm intuitive correlations between variables and define a potential main article\n",
    "- [x] Define a primitive set of clichés, a performance metric and verify if the passing paths using clichés have better performance\n",
    "- [x] Study a particular cliché and the categorization of the articles linked to it and our main article\n",
    "\n",
    "In the code below, we'll mainly be using the graph data from the Wikispeedia dataset. \n",
    "In particular, we use the finished paths, a little bit the unfinished paths, the adjacency matrix and theoretical shortest paths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tudoroancea/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tudoroancea/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/tudoroancea/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from cliches import *\n",
    "from data_augmentation import *\n",
    "from data_quantity_analysis import *\n",
    "from plot_helpers import *\n",
    "from preprocessing import *\n",
    "\n",
    "np.random.seed(127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the data has not been downloaded yet\n",
    "if not os.path.exists('data'):\n",
    "    %run download_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    articles,\n",
    "    categories,\n",
    "    links,\n",
    "    paths_finished,\n",
    "    paths_unfinished,\n",
    ") = import_and_clean_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data quantity analysis - exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by exploring the data set to get an overview of the data and the information it provides. As a first step, we're trying to create graphs that could potentially give us information about how players play and think."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the aim of our project is to look at the role of clichés in the choice of artworks by users and, more generally, the role they play in information, we begin by looking at the sub-sets of data that contain the most information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we look at the 100 most visited articles by players and then the 100 most used targets, both among the finished paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_visited_articles(paths_finished, categories, show=True, html_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_target_articles(paths_finished, categories, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then look at the distribution of the length and duration of the finished paths to see if these correspond to a normal trend or if there are particular features to be analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_duration_distribution(paths_finished, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_length_distribution(paths_finished, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at distributions with a single valuer, we'll look at the links between several valuers: in particular, we'll look at the interaction between the length of the path and the length of the game's duration, and then the interaction between the score given to the chmin and its length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_length_vs_duration(paths_finished, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_vs_path_length(paths_finished, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the previous two plots, we could hypothesize that the length of the path is correlated to the duration of the game and its rating, simply based on the apparent monotonicity of the data.\n",
    "Both these interpretations are intuitive but we should perform a statistical regressions and tests to confirm them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may be interested in another more objective metrics. In other word, we try to compare how the difference between the actual path taken and the shortest (theoretical) path behaves with respect to the rating given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(\n",
    "    data=paths_finished,\n",
    "    y=\"diff_length\",\n",
    "    kind=\"bar\",\n",
    "    palette=\"coolwarm\",\n",
    "    hue=\"rating\",\n",
    ")\n",
    "ax.despine(left=True)\n",
    "plt.title(\"Difference between path length and the shortest path length, depending on the rating\")\n",
    "plt.xlabel(\"Rating (where 0 is no rating)\")\n",
    "plt.ylabel(\"Length difference\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, there seems to be some difference between the difference of length of paths for different ratings. Notice that compared to the path lengths for different rating, the difference between rating 4 vs 5 in more siginificant in the plot of difference in length. Indeed, the error bars do not overlap in these ratings.\n",
    "\n",
    "For this reason, we will choose this difference between the path length and the shortest path length as our performance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific example: the United Kingdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at the data as a whole, let's take a closer look at one data set in particular, that of United Kingdom. This will allow us to define a set of snapshots for this particular area. We've decided to use United Kingdom as an example because it's one of the most visited items in the dataset and as one of our european neighbors, we can easily find clichés that are true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_article = \"United_Kingdom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_in_out_neighbors(paths_finished, paths_unfinished, main_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_position_percentage(paths_finished, main_article, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In generality, we can't really infer any particular distribution from the data. However, in future analysis we could try to fit distributions when we consider the position of the main article conditonally on additional events (e.g. the path also contains a particular cliché)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define main_article for analysis: \n",
    "main_article = \"United_Kingdom\"\n",
    "\n",
    "# only keep rows such that main_article in path\n",
    "around_main_article = get_df_main_article(paths_finished, main_article=main_article).copy(deep=True)\n",
    "\n",
    "# get category of the main_article\n",
    "around_main_article[\"main_article_category\"] = around_main_article[\"path\"].apply(lambda path: get_category_main_article(main_article, path, categories))\n",
    "\n",
    "# article juste before/just after main_article\n",
    "# TODO: function to be improved/discussed. What do we want to do with \"<\"?\n",
    "around_main_article[\"around_path\"] = around_main_article[\"path\"].apply(\n",
    "    lambda path: get_index_main_article_in(main_article, path)\n",
    ")\n",
    "\n",
    "# update initial/target_article, initial/target_category\n",
    "around_main_article[\"around_IA\"] = around_main_article[\"around_path\"].apply(\n",
    "    lambda path: path[0]\n",
    ")\n",
    "around_main_article[\"around_TA\"] = around_main_article[\"around_path\"].apply(\n",
    "    lambda path: path[-1]\n",
    ")\n",
    "around_main_article[\"around_IC\"] = around_main_article[\"around_IA\"].apply(\n",
    "    lambda article: categories[categories[\"article\"] == article][\"category1\"].values\n",
    ")\n",
    "around_main_article[\"around_TC\"] = around_main_article[\"around_TA\"].apply(\n",
    "    lambda article: categories[categories[\"article\"] == article][\"category1\"].values\n",
    ")\n",
    "\n",
    "around_main_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only 10% most frequent articles just after main_article\n",
    "most_frequent_before = around_main_article[\"around_IA\"].value_counts(normalize=True)\n",
    "plot_most_frequent_articles(most_frequent_before, \"precede\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only 10% most frequent articles just after main_article\n",
    "most_frequent_before = around_main_article[\"around_IA\"].value_counts(normalize=True)\n",
    "plot_most_frequent_articles(most_frequent_before, \"precede\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our cliches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cliches preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will define and extract data from the clichés. This will enable us to carry out analyses to discover whether or not there are any links between our chosen subject and the clichés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical tests for difference of path length for different cliches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to find some statistical evidence of whether clichés influence the length of the path from the initial article to the target article. From the previous exploration, it seems that the difference of path length between the actual path taken and the shortest (theoretical) path is a \"good\" metric of the player's performance.\n",
    "\n",
    "So the idea is to select all the rows in `paths_finished` that contain the main article `United_Kingdom`. The selection of clichés remains to be done in an unbiased way. For now, we select \"cliché\" articles from the plots just above (see selected cliché articles below)[^1]. Next, it makes sense to compare difference in length for a given rating. Otherwise, as stated earlier, \"harder\" articles seem to tend to have higher difference in length and hence we would be comparing different categories.\n",
    "\n",
    "To check whether there is a statistical difference, we compute a Welch's t-test. Indeed, given a rating, we assume that our observations are independant. Additionally, it seems that the difference in length among a rating between those who went through cliché articles and those who did not do not have same variance. \n",
    "\n",
    "[^1]: We are looking into different ways to retrieve cliché articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(12, 6), sharey=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    temp = paths_finished[paths_finished[\"rating\"] == i + 1][\"diff_length\"]\n",
    "    ax.hist(temp, bins=20, density=True)\n",
    "    ax.set_xlabel(\"difference in length\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"density value\")\n",
    "    ax.set_title(f\"Rating {i+1}\")\n",
    "\n",
    "# make room for suptitle\n",
    "fig.subplots_adjust(top=0.9)\n",
    "fig.suptitle(\n",
    "    \"Distribution of the difference in length between the path and the shortest path, depending on the rating\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the higher the rating, the higher the variance. Additionally, it is worth noting that the data is imbalanced among the ratings.\n",
    "\n",
    "Above, we have compared the variance between different ratings but not among a rating between the paths that go through cliché articles and those that do not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select some cliches\n",
    "main_article_cliches = [\n",
    "    \"William_Shakespeare\",\n",
    "    \"Harry_Potter\",\n",
    "    \"BBC\",\n",
    "    \"Winston_Churchill\",\n",
    "    \"The_Beatles\",\n",
    "    \"Elizabeth_II_of_the_United_Kingdom\",\n",
    "    \"Flower\",\n",
    "    \"British_monarchy\",\n",
    "    \"British_Empire\",\n",
    "    \"Prime_Minister_of_the_United_Kingdom\",\n",
    "    \"Pound_sterling\",\n",
    "    \"London\",\n",
    "]\n",
    "\n",
    "ratings = np.arange(1, 6, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create dataframe\n",
    "test_cliche = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"main_article\",\n",
    "        \"cliche\",\n",
    "        \"rating\",\n",
    "        \"mean_cliche\",\n",
    "        \"mean_nocliche\",\n",
    "        \"shape_cliche\",\n",
    "        \"shape_nocliche\",\n",
    "        \"statistic\",\n",
    "        \"p_value\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# test different ratings and cliches\n",
    "for rating in ratings:\n",
    "    for cliche in main_article_cliches:\n",
    "        (\n",
    "            stat,\n",
    "            p,\n",
    "            mean_path_cliche,\n",
    "            mean_path_nocliche,\n",
    "            shape_cliche,\n",
    "            shape_nocliche,\n",
    "        ) = test_difference_path_length_cliche(\n",
    "            paths_finished, rating, cliche, main_article, False, False\n",
    "        )\n",
    "        test_cliche.loc[test_cliche.shape[0]] = [\n",
    "            main_article,\n",
    "            cliche,\n",
    "            rating,\n",
    "            mean_path_cliche,\n",
    "            mean_path_nocliche,\n",
    "            shape_cliche,\n",
    "            shape_nocliche,\n",
    "            stat,\n",
    "            p,\n",
    "        ]\n",
    "\n",
    "test_cliche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in most cases, we do not have enough data to compare. However, those going through the article `London` are *almost* statistically significantly (at $\\alpha=0.05$) more performant that others fore rating 1 and 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categories and clichés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider here the finished paths passing through our chosen main article \"United_Kingdom\".\n",
    "We enumerate all the categories of the articles at most 3 steps away from the main article on these paths and construct a bar chart to visualize their number of occurences.\n",
    "We further color each category bar depending on whether \"United_Kingdom\" belongs to it or not.\n",
    "Finally, arrows are used to indicate specific categories of a given cliché (here “William_Shakespeare”, drawn from the list created in the previous section). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories, subcategories1, subcategories2, subcatgeories3 = separate_categories(main_article, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_results(paths_finished, main_article, categories, all_categories, [\"category1\", \"category2\", \"category3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bar plot shows that:\n",
    "- the categories that \"United_Kingdom\" belongs to are (among) the most frequent ones, which is not surprising given that the hyperlinks in an article should redirect to related articles, and given that the players often rely on semantic links to find the target article.\n",
    "- if we look at the categories of our designated cliché \"William_Shakespeare\", they are quite frequent, although not coinciding with the \"United_Kingdom\"'s catgeories. This is not surprising either, because of the very nature of the two articles: one of them is a country, the other one is a playwright. However, we can see that the categories of \"William_Shakespeare\" are quite frequent, which is a good sign for our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen previously, we do not have much data to extract meaningful results. So, we may want to augment our data.\n",
    "\n",
    "The pipeline for augmenting our data is the following: we analyze the clichés around the UK in the SeeGull data set as well as the content of the articles and try to link them together. More precisely, we retreive the \"topics\" of the clichés from the SeeGull data set (eg alcohol, liquid etc.) and do the same for each articles.\n",
    "\n",
    "So far, we have two sets of topics: one from the SeeGull dataset, and one for each article from the main data base. We add article to our list of cliché articles if there are \"enough\" topics in common.\n",
    "\n",
    "The main part of this analysis is to make sure that is pipeline is sensible:\n",
    "- does is make sense to compare the two sets of topics? \n",
    "- does it actually augmente the data (statistical significance for the t-tests above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from empath import Empath\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, PlaintextCorpusReader\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# download if first time running library\n",
    "download = True\n",
    "\n",
    "if download:\n",
    "    nltk.download(\"punkt\")\n",
    "    nltk.download(\"stopwords\")\n",
    "    nltk.download(\"wordnet\")\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "ARTICLES_PLAIN_TEXT_PATH = os.path.join(DATA_PATH, \"articles_plain_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeeGull topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_topics_seegull = generate_seegull_topics([\"British\", \"English\"], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikispeedia dataset topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do the same but with the wikispeedia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_topics = load_articles_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles' content with proper noun\n",
    "\n",
    "The idea is to look at the content of the articles and compare it to the reference article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First attempt\n",
    "First attempt takes the content in general without any filtering.\n",
    "We can first test the topics on a small subset of articles to check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare 10 random articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(16)\n",
    "\n",
    "uk_topics_row = article_topics[article_topics[\"article_name\"] == \"United_Kingdom\"]\n",
    "# Randomly select 10 articles\n",
    "random_articles = article_topics.sample(n=10)\n",
    "\n",
    "for index, row in random_articles.iterrows():\n",
    "    common_topics = set(row[\"topics\"]) & set(uk_topics_row[\"topics\"].values[0])\n",
    "    print(\n",
    "        f\"Common topics for {row['article_name']} and United Kingdom: {common_topics}\"\n",
    "    )\n",
    "\n",
    "# Save 'topics' column of random_articles to a CSV file\n",
    "# random_articles[[\"article_name\", \"topics\"]].to_csv(\n",
    "#     os.path.join(DATA_PATH, \"random_articles_topics.csv\"), index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /!\\ dataset is stored in \"top_50_common_topics.csv\" file\n",
    "\n",
    "uk_topics = uk_topics_row.iloc[0][\"topics\"]\n",
    "\n",
    "# Compare topics for all articles in the dataset\n",
    "common_article_topics = []\n",
    "\n",
    "for index, row in article_topics.iterrows():\n",
    "    if row[\"article_name\"] == \"United_Kingdom\":\n",
    "        continue\n",
    "    common_topics = set(row[\"topics\"]) & set(uk_topics_row[\"topics\"].values[0])\n",
    "    if common_topics:\n",
    "        common_article_topics.append(\n",
    "            {\"article_name\": row[\"article_name\"], \"common_topics\": common_topics}\n",
    "        )\n",
    "\n",
    "# Sort comparisons based on the number of common topics\n",
    "common_article_topics.sort(key=lambda x: len(x[\"common_topics\"]), reverse=True)\n",
    "\n",
    "common_article_topics = pd.DataFrame(common_article_topics)\n",
    "display(common_article_topics.head(20))\n",
    "\n",
    "# Print the top 5 comparisons\n",
    "# print(\"Top 5 comparisons with most common topics:\")\n",
    "# for i in range(min(5, len(common_article_topics))):\n",
    "#     print(\n",
    "#         f\"{common_article_topics[i]['article_name']} and United Kingdom: {common_article_topics[i]['common_topics']}\"\n",
    "#     )\n",
    "\n",
    "# Save the top 50 comparisons to a CSV file\n",
    "# top_50_comparisons = comparisons_with_common_topics[:50]\n",
    "# if top_50_comparisons:\n",
    "#     df_top_50_comparisons = pd.DataFrame(top_50_comparisons)\n",
    "#     df_top_50_comparisons.to_csv(os.path.join(DATA_PATH , \"top_50_common_topics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the common topics are very general and a lot of articles have them. So we need to filter the content of the articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the common topics for articles 12th_century, Armand_Jean_du_Plessis%2C_Cardinal_Richelieu, Babylonia\n",
    "concrete_examples = common_article_topics[\n",
    "    common_article_topics[\"article_name\"].isin(\n",
    "        [\"12th_century\", \"Armand_Jean_du_Plessis%2C_Cardinal_Richelieu\", \"Babylonia\"]\n",
    "    )\n",
    "]\n",
    "for _, row in concrete_examples.iterrows():\n",
    "    print(f\"{row['article_name']} and United Kingdom: {row['common_topics']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second attempt\n",
    "Look at the most common words and proper nouns in contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_and_pos[\"article_name\"] = tokens_and_pos[\"article_name\"].str.replace(\".txt\", \"\")\n",
    "tokens_and_pos.to_csv(os.path.join(data_path, \"article_token_pos.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "tokens_and_pos = load_token_pos()\n",
    "\n",
    "# Filter rows related to the target article\n",
    "target_article_name = \"United_Kingdom\"\n",
    "target_article_data = tokens_and_pos[\n",
    "    tokens_and_pos[\"article_name\"] == target_article_name\n",
    "]\n",
    "\n",
    "# Extract the top 10 PROPN tokens for the target article\n",
    "target_proper_nouns = [\n",
    "    token[0]\n",
    "    for tokens_pos_list in target_article_data[\"tokens_pos\"]\n",
    "    for token in tokens_pos_list\n",
    "    if token[1] == \"PROPN\"\n",
    "]\n",
    "top_target_proper_nouns = [\n",
    "    item[0] for item in Counter(target_proper_nouns).most_common(10)\n",
    "]\n",
    "\n",
    "# Initialize a list to store common proper nouns\n",
    "common_proper_nouns = []\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in tokens_and_pos.iterrows():\n",
    "    # Extract the top 10 PROPN tokens for each article\n",
    "    if row[\"article_name\"] == target_article_name:\n",
    "        continue\n",
    "    article_proper_nouns = [\n",
    "        token[0] for token in row[\"tokens_pos\"] if token[1] == \"PROPN\"\n",
    "    ]\n",
    "    top_article_proper_nouns = [\n",
    "        item[0] for item in Counter(article_proper_nouns).most_common(10)\n",
    "    ]\n",
    "\n",
    "    # Compare with the top PROPN tokens of the target article\n",
    "    common_tokens = set(top_article_proper_nouns) & set(top_target_proper_nouns)\n",
    "\n",
    "    # Store the results\n",
    "    common_proper_nouns.append(\n",
    "        {\"article_name\": row[\"article_name\"], \"common_propnouns\": common_tokens}\n",
    "    )\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "common_proper_nouns_df = pd.DataFrame(common_proper_nouns)\n",
    "\n",
    "# Sort the DataFrame based on the number of common proper nouns\n",
    "common_proper_nouns_df = common_proper_nouns_df.sort_values(\n",
    "    by=\"common_propnouns\", key=lambda x: x.str.len(), ascending=False\n",
    ")\n",
    "\n",
    "# Print the top 5 comparisons\n",
    "print(\"Top 5 comparisons with most common proper nouns:\")\n",
    "for i in range(min(5, len(common_proper_nouns_df))):\n",
    "    print(\n",
    "        f\"{common_proper_nouns_df.iloc[i]['article_name']} and {target_article_name}: {common_proper_nouns_df.iloc[i]['common_propnouns']}\"\n",
    "    )\n",
    "\n",
    "# Save the top comparisons to a CSV file\n",
    "top_comparisons = common_proper_nouns_df.head(50)\n",
    "# if not top_comparisons.empty:\n",
    "#     top_comparisons.to_csv(\n",
    "#         os.path.join(data_path, \"top_proper_noun_comparisons.csv\"), index=False\n",
    "#     )\n",
    "#     print(\n",
    "#         f\"Top comparisons with most common proper nouns saved to {data_path}top_proper_noun_comparisons.csv\"\n",
    "#     )\n",
    "# else:\n",
    "#     print(\"No common proper nouns found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_proper_nouns_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles' content with links \n",
    "(pushed from Martin's work)\n",
    "\n",
    "Idea is to compare the `linkTarget` in the reference article (UK) and other articles. Articles that satisfy \"some conditions\" (to be defined) are selected as clichés articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tudoroancea/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tudoroancea/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/tudoroancea/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_name</th>\n",
       "      <th>common_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Áedán_mac_Gabráin</td>\n",
       "      <td>[Orkney, Isle_of_Man, Monarchy, Great_Britain,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland</td>\n",
       "      <td>[Time_zone, World_War_II, Currency, European_U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Édouard_Manet</td>\n",
       "      <td>[Germany, United_States_dollar, Italy, France]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Éire</td>\n",
       "      <td>[English_language, Ireland, Republic_of_Irelan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Óengus_I_of_the_Picts</td>\n",
       "      <td>[Lion, Great_Britain, Ireland, Scotland, England]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>€2_commemorative_coins</td>\n",
       "      <td>[United_Nations, Ireland, Italy, European_Unio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10th_century</td>\n",
       "      <td>[Lion, Monarchy, Italy, India, Scotland, Germa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11th_century</td>\n",
       "      <td>[England, France, India, Novel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12th_century</td>\n",
       "      <td>[England, Ireland, France, India]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13th_century</td>\n",
       "      <td>[Europe, Islam, Scotland, Isle_of_Man]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14th_century</td>\n",
       "      <td>[Europe, Italy, Christianity, Islam, England, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15th_Marine_Expeditionary_Unit</td>\n",
       "      <td>[Somalia, World_War_II, Pakistan, Royal_Marines]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15th_century</td>\n",
       "      <td>[Europe, Spain, France, India]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16_Cygni</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16_Cygni_Bb</td>\n",
       "      <td>[Earth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16th_century</td>\n",
       "      <td>[France, Europe, Henry_VIII_of_England, Irelan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1755_Lisbon_earthquake</td>\n",
       "      <td>[Europe, England, Ireland, Atlantic_Ocean]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17th_century</td>\n",
       "      <td>[Henry_Purcell, France, Charles_II_of_England,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1896_Summer_Olympics</td>\n",
       "      <td>[London, Olympic_Games, Europe, British_Empire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18th_century</td>\n",
       "      <td>[London, Industrial_Revolution, Prime_Minister...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      article_name  \\\n",
       "0                Áedán_mac_Gabráin   \n",
       "1                            Åland   \n",
       "2                    Édouard_Manet   \n",
       "3                             Éire   \n",
       "4            Óengus_I_of_the_Picts   \n",
       "5           €2_commemorative_coins   \n",
       "6                     10th_century   \n",
       "7                     11th_century   \n",
       "8                     12th_century   \n",
       "9                     13th_century   \n",
       "10                    14th_century   \n",
       "11  15th_Marine_Expeditionary_Unit   \n",
       "12                    15th_century   \n",
       "13                        16_Cygni   \n",
       "14                     16_Cygni_Bb   \n",
       "15                    16th_century   \n",
       "16          1755_Lisbon_earthquake   \n",
       "17                    17th_century   \n",
       "18            1896_Summer_Olympics   \n",
       "19                    18th_century   \n",
       "\n",
       "                                         common_links  \n",
       "0   [Orkney, Isle_of_Man, Monarchy, Great_Britain,...  \n",
       "1   [Time_zone, World_War_II, Currency, European_U...  \n",
       "2      [Germany, United_States_dollar, Italy, France]  \n",
       "3   [English_language, Ireland, Republic_of_Irelan...  \n",
       "4   [Lion, Great_Britain, Ireland, Scotland, England]  \n",
       "5   [United_Nations, Ireland, Italy, European_Unio...  \n",
       "6   [Lion, Monarchy, Italy, India, Scotland, Germa...  \n",
       "7                     [England, France, India, Novel]  \n",
       "8                   [England, Ireland, France, India]  \n",
       "9              [Europe, Islam, Scotland, Isle_of_Man]  \n",
       "10  [Europe, Italy, Christianity, Islam, England, ...  \n",
       "11   [Somalia, World_War_II, Pakistan, Royal_Marines]  \n",
       "12                     [Europe, Spain, France, India]  \n",
       "13                                                 []  \n",
       "14                                            [Earth]  \n",
       "15  [France, Europe, Henry_VIII_of_England, Irelan...  \n",
       "16         [Europe, England, Ireland, Atlantic_Ocean]  \n",
       "17  [Henry_Purcell, France, Charles_II_of_England,...  \n",
       "18  [London, Olympic_Games, Europe, British_Empire...  \n",
       "19  [London, Industrial_Revolution, Prime_Minister...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the precomputed data\n",
    "links_common = load_links_common()\n",
    "links_common.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Common links between Red_Kite and United Kingdom: ['Europe', 'Wales', 'Scotland', 'Germany', 'England']\n",
      "<class 'list'>\n",
      "Common links between Magnesium and United Kingdom: ['DNA', 'Earth', 'Hydrogen', 'Scotland', 'Steel', 'Electron']\n",
      "<class 'list'>\n",
      "Common links between Honduras and United Kingdom: ['Time_zone', 'English_language', 'Currency', 'Television', 'United_States_dollar', 'List_of_countries_by_system_of_government', 'Spain']\n"
     ]
    }
   ],
   "source": [
    "# find 3 random sampes\n",
    "random_samples = links_common.sample(n=3)\n",
    "for _, row in random_samples.iterrows():\n",
    "    print(type(row[\"common_links\"]))\n",
    "    print(\n",
    "        f\"Common links between {row['article_name']} and United Kingdom: {row['common_links']}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_name</th>\n",
       "      <th>common_links</th>\n",
       "      <th>nbr_common_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>England</td>\n",
       "      <td>[Industrial_Revolution, Benjamin_Britten, Engl...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3642</th>\n",
       "      <td>Scotland</td>\n",
       "      <td>[Industrial_Revolution, Parliament_of_the_Unit...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>United_States</td>\n",
       "      <td>[Natural_gas, World_War_II, NATO, World_Herita...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>British_monarchy</td>\n",
       "      <td>[Parliament_of_the_United_Kingdom, World_War_I...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>London</td>\n",
       "      <td>[Parliament_of_the_United_Kingdom, World_War_I...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>Elizabeth_II_of_the_United_Kingdom</td>\n",
       "      <td>[British_monarchy, World_War_II, Northern_Irel...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>British_Isles_(terminology)</td>\n",
       "      <td>[Scottish_Gaelic_language, Northern_Ireland, A...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>Europe</td>\n",
       "      <td>[Industrial_Revolution, World_War_II, NATO, No...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>English_language</td>\n",
       "      <td>[World_War_II, Northern_Ireland, Jersey, Briti...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>Germany</td>\n",
       "      <td>[Natural_gas, Industrial_Revolution, World_War...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>British_Empire</td>\n",
       "      <td>[Industrial_Revolution, World_War_II, English_...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>European_Union</td>\n",
       "      <td>[Natural_gas, World_War_II, NATO, English_lang...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>Wales</td>\n",
       "      <td>[Parliament_of_the_United_Kingdom, British_mon...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>British_Isles</td>\n",
       "      <td>[Northern_Ireland, Irish_Sea, Atlantic_Ocean, ...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>Manchester</td>\n",
       "      <td>[Industrial_Revolution, World_War_II, World_He...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>Northern_Ireland</td>\n",
       "      <td>[British_monarchy, English_language, Constitut...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>[Natural_gas, Parliament_of_the_United_Kingdom...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>[World_War_II, NATO, English_language, Constit...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>Driving_on_the_left_or_right</td>\n",
       "      <td>[World_War_II, Jersey, France, London, Argenti...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Commonwealth_Games</td>\n",
       "      <td>[English_language, Northern_Ireland, Jersey, G...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            article_name  \\\n",
       "1379                             England   \n",
       "3642                            Scotland   \n",
       "4282                       United_States   \n",
       "700                     British_monarchy   \n",
       "2530                              London   \n",
       "1360  Elizabeth_II_of_the_United_Kingdom   \n",
       "698          British_Isles_(terminology)   \n",
       "1427                              Europe   \n",
       "1383                    English_language   \n",
       "1688                             Germany   \n",
       "693                       British_Empire   \n",
       "1433                      European_Union   \n",
       "4380                               Wales   \n",
       "697                        British_Isles   \n",
       "2622                          Manchester   \n",
       "3008                    Northern_Ireland   \n",
       "2143                             Ireland   \n",
       "2946                         Netherlands   \n",
       "1242        Driving_on_the_left_or_right   \n",
       "995                   Commonwealth_Games   \n",
       "\n",
       "                                           common_links  nbr_common_links  \n",
       "1379  [Industrial_Revolution, Benjamin_Britten, Engl...                63  \n",
       "3642  [Industrial_Revolution, Parliament_of_the_Unit...                57  \n",
       "4282  [Natural_gas, World_War_II, NATO, World_Herita...                42  \n",
       "700   [Parliament_of_the_United_Kingdom, World_War_I...                35  \n",
       "2530  [Parliament_of_the_United_Kingdom, World_War_I...                33  \n",
       "1360  [British_monarchy, World_War_II, Northern_Irel...                32  \n",
       "698   [Scottish_Gaelic_language, Northern_Ireland, A...                32  \n",
       "1427  [Industrial_Revolution, World_War_II, NATO, No...                32  \n",
       "1383  [World_War_II, Northern_Ireland, Jersey, Briti...                30  \n",
       "1688  [Natural_gas, Industrial_Revolution, World_War...                29  \n",
       "693   [Industrial_Revolution, World_War_II, English_...                29  \n",
       "1433  [Natural_gas, World_War_II, NATO, English_lang...                29  \n",
       "4380  [Parliament_of_the_United_Kingdom, British_mon...                29  \n",
       "697   [Northern_Ireland, Irish_Sea, Atlantic_Ocean, ...                28  \n",
       "2622  [Industrial_Revolution, World_War_II, World_He...                28  \n",
       "3008  [British_monarchy, English_language, Constitut...                27  \n",
       "2143  [Natural_gas, Parliament_of_the_United_Kingdom...                27  \n",
       "2946  [World_War_II, NATO, English_language, Constit...                26  \n",
       "1242  [World_War_II, Jersey, France, London, Argenti...                26  \n",
       "995   [English_language, Northern_Ireland, Jersey, G...                26  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_common[\"nbr_common_links\"] = links_common[\"common_links\"].apply(len)\n",
    "links_common.sort_values(\"nbr_common_links\", ascending=False, inplace=True)\n",
    "links_common.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of locations appear. We may want to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create nlp object\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract countries and cities\n",
    "locations = [(ent.text, ent.label_) for ent in doc.ents if ent.label_ in ['GPE', 'LOC']]\n",
    "\n",
    "# filter out duplicates\n",
    "unique_locations1 = (set(locations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentary for us (french):\n",
    "- normaliser les scores\n",
    "- comment gerer les pays?\n",
    "- combiner les deux methodes anna/martin ? comment ? threshold selection des cliches\n",
    "- regarder les cliches selectionner par NLP et checker s'ils sont utilisés dans les paths\n",
    "- commenter sur les cliches jamais pris. Pourquoi?\n",
    "\n",
    "Prompt ChatGPT: give me clichés about the UK using bullet points and at most 5 words by cliché\n",
    "- Tea time obsession\n",
    "- Polite queueing traditions\n",
    "- Rainy weather stereotypes\n",
    "- Double-decker buses iconic\n",
    "- Sherlock Holmes detective legacy\n",
    "- Royal family fascination\n",
    "- Soccer (football) mania\n",
    "- Pubs and fish & chips\n",
    "- Mysterious foggy landscapes\n",
    "- Love for proper etiquette\n",
    "- Red phone booths everywhere\n",
    "- Beatles' timeless musical influence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisit of statistical tests with data augmentation/clichés selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize number of links in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number of links by article\n",
    "df_nbr_links_by_articles = pd.pivot_table(\n",
    "    links, values=[\"linkTarget\"], index=[\"linkSource\"], aggfunc=\"count\"\n",
    ").sort_values(\"linkTarget\")\n",
    "display(df_nbr_links_by_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep articles with at least one in common\n",
    "no_zero_common_articles = common_links_reference[\n",
    "    ~np.where(common_links_reference[\"nbr_common_articles\"] == 0, True, False)\n",
    "].sort_values(\"nbr_common_articles\")\n",
    "display(no_zero_common_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_zero_common_articles_normalized_links = no_zero_common_articles.copy(deep=True)\n",
    "\n",
    "\n",
    "def normalize_links(article, size_common_links, size_total_links):\n",
    "    # normalize number of links in common by number of links in article\n",
    "    total_links_article = size_total_links.loc[article].values[0]\n",
    "    return size_common_links / total_links_article\n",
    "\n",
    "\n",
    "# normalize number of links in common by number of links on article considered\n",
    "no_zero_common_articles_normalized_links[\"normalized_common\"] = no_zero_common_articles[\n",
    "    [\"article\", \"nbr_common_articles\"]\n",
    "].apply(\n",
    "    lambda row: normalize_links(\n",
    "        row[\"article\"], row[\"nbr_common_articles\"], df_nbr_links_by_articles\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "display(no_zero_common_articles_normalized_links.sort_values(\"normalized_common\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove max/min values of normalization. How to keep the correct clichés?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the statistical tests\n",
    "\n",
    "Does not look good with normalization. Statistical analysis without normalization using data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_articles_normalized = no_zero_common_articles_normalized_links.sort_values(\"nbr_common_articles\", ascending=False).reset_index(drop=True).copy(deep=True)\n",
    "common_articles_normalized[1:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to remove countries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_finished_use_cliche = paths_finished.copy(deep=True)\n",
    "\n",
    "# define the cliches\n",
    "set_cliches = common_articles_normalized[\"article\"][1:20]\n",
    "\n",
    "# check which paths use cliches\n",
    "paths_finished_use_cliche[\"uses_cliche\"] = paths_finished[\"path\"].apply(\n",
    "    lambda path: len(set(path) & set(set_cliches)) != 0\n",
    ")\n",
    "paths_finished_use_cliche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the statistical tests by rating by comparing difference of length for those using cliches and those who do not\n",
    "# here only for rating 1 for test\n",
    "rating = 1\n",
    "df_statistics_test_rating1 = (\n",
    "    paths_finished_use_cliche.groupby([\"rating\", \"uses_cliche\"])[[\"diff_length\"]]\n",
    "    .apply(lambda x: x)\n",
    "    .loc[rating]\n",
    ")\n",
    "df_statistics_test_rating1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stat, p = stats.ttest_ind(\n",
    "    df_statistics_test_rating1.loc[True].to_numpy().reshape(df_statistics_test_rating1.loc[True].shape[0]),\n",
    "    df_statistics_test_rating1.loc[False].to_numpy().reshape(df_statistics_test_rating1.loc[False].shape[0]),\n",
    "    equal_var=False,\n",
    "    alternative=\"two-sided\",\n",
    ")\n",
    "\n",
    "print(f\"stat={stat}, pvalue={p}\")\n",
    "print(\n",
    "    \"Result is significant at 0.05\" if p < 0.05 else \"Result is not significant\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
